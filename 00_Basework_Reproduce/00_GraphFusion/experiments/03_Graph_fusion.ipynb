{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 281 candidate triples\n"
     ]
    }
   ],
   "source": [
    "# Load relation definitions (adjust the file path as needed)\n",
    "with open(\"inputs/relation_types.json\", \"r\") as f:\n",
    "    relation_def = json.load(f)\n",
    "\n",
    "# Create a mapping from relation type to id\n",
    "relation_2_id = {rel: idx for idx, rel in enumerate(list(relation_def.keys()))}\n",
    "\n",
    "# Load candidate triples from your candidate file (output from step 2)\n",
    "candidate_triples = []\n",
    "input_file = \"outputs/sample/triples_sample.json\"  # adjust as necessary\n",
    "with open(input_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        t = json.loads(line)\n",
    "        candidate_triples.append((t['s'], t['p'], t['o']))\n",
    "\n",
    "print(f\"Loaded {len(candidate_triples)} candidate triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural language explanation', 'Evaluate-for', 'model reasoning'),\n",
       " ('natural language explanation',\n",
       "  'Evaluate-for',\n",
       "  'classification performance'),\n",
       " ('natural language explanation', 'Used-for', 'improving classification'),\n",
       " ('natural language explanation', 'Used-for', 'justifying predictions'),\n",
       " ('natural language explanation', 'Evaluate-for', 'inconsistencies detection'),\n",
       " ('natural language explanation', 'Evaluate-for', 'gender-fairness'),\n",
       " ('natural language explanation', 'Evaluate-for', 'ambiguity resolution'),\n",
       " ('natural language explanation', 'Part-of', 'natural language processing'),\n",
       " ('natural language explanation', 'Hyponym-Of', 'text explanation'),\n",
       " ('natural language explanation', 'Compare', 'text-to-image disambiguation'),\n",
       " ('natural language explanation',\n",
       "  'Used-for',\n",
       "  'enhancing language representation'),\n",
       " ('natural language explanation', 'Used-for', 'guiding model reasoning'),\n",
       " ('event relation', 'Used-for', 'event detection'),\n",
       " ('event detection', 'Used-for', 'biographical event detection'),\n",
       " ('event relation', 'Used-for', 'document-level relation extraction'),\n",
       " ('event relation', 'Used-for', 'discourse analysis'),\n",
       " ('event detection', 'Used-for', 'clinical event extraction'),\n",
       " ('event detection', 'Part-of', 'event extraction'),\n",
       " ('document-level relation extraction', 'Part-of', 'event extraction'),\n",
       " ('biographical event detection', 'Part-of', 'event extraction'),\n",
       " ('clinical event extraction', 'Part-of', 'event extraction'),\n",
       " ('event extraction', 'Used-for', 'knowledge graph construction'),\n",
       " ('shot learning', 'Hyponym-Of', 'zero-shot learning'),\n",
       " ('zero-shot learning', 'Part-of', 'in-context learning'),\n",
       " ('Perplexity Selection (Perplection)',\n",
       "  'Used-for',\n",
       "  'zero-shot text classification'),\n",
       " ('Hypernetworks for INstruction Tuning (HINT)',\n",
       "  'Used-for',\n",
       "  'enhancing zero-shot learning performance'),\n",
       " ('PESCO', 'Used-for', 'improving zero-shot text classification'),\n",
       " ('IDRISI-RA', 'Evaluate-for', 'zero-shot learning in low resource languages'),\n",
       " ('in-context learning',\n",
       "  'Is-a-Prerequisite-of',\n",
       "  'effective few-shot learning'),\n",
       " ('large language models', 'Evaluate-for', 'in-context learning performance'),\n",
       " ('multi-task learning',\n",
       "  'Used-for',\n",
       "  'enhancing conversational agent skills in zero-shot contexts'),\n",
       " ('argument extraction', 'Used-for', 'attribute extraction'),\n",
       " ('argument extraction', 'Part-of', 'Event Argument Extraction (EAE)'),\n",
       " ('argument extraction', 'Evaluate-for', 'model generalizability'),\n",
       " ('Event Argument Extraction (EAE)', 'Part-of', 'event extraction'),\n",
       " ('Event Argument Extraction (EAE)',\n",
       "  'Evaluate-for',\n",
       "  'document-level extraction'),\n",
       " ('Event Argument Extraction (EAE)',\n",
       "  'Is-a-Prerequisite-of',\n",
       "  'document-level multi-event extraction'),\n",
       " ('Event Argument Extraction (EAE)',\n",
       "  'Used-for',\n",
       "  'identifying event arguments'),\n",
       " ('document-level extraction', 'Compare', 'sentence-level extraction'),\n",
       " ('document-level extraction',\n",
       "  'Evaluate-for',\n",
       "  'handling long-range dependencies'),\n",
       " ('AMPERE', 'Used-for', 'generation-based Event Argument Extraction'),\n",
       " ('AMPERE', 'Evaluate-for', 'improving generation'),\n",
       " ('TAGPRIME', 'Used-for', 'relational structure extraction'),\n",
       " ('TAGPRIME', 'Evaluate-for', 'multiple NLP tasks'),\n",
       " ('DICE', 'Used-for', 'clinical event extraction'),\n",
       " ('DICE', 'Evaluate-for', 'news domain event extraction'),\n",
       " ('TBO', 'Used-for', 'offensive language identification'),\n",
       " ('TBO', 'Evaluate-for', 'comparing model performance'),\n",
       " ('QGA-EE', 'Used-for', 'event extraction'),\n",
       " ('DIONYSUS', 'Used-for', 'summarizing dialogues'),\n",
       " ('Compo', 'Used-for', 'generating diverse conversation-summary pairs'),\n",
       " ('CSJ', 'Used-for', 'cross-lingual scientific summarization'),\n",
       " ('SSR', 'Used-for', 'cross-lingual simplified science summaries'),\n",
       " ('QAmden', 'Used-for', 'multi-document tasks'),\n",
       " ('QAmden', 'Used-for', 'multi-document summarization'),\n",
       " ('QAmden', 'Used-for', 'query-focused summarization'),\n",
       " ('QAmden', 'Used-for', 'multi-document QA'),\n",
       " ('ExtEval', 'Used-for', 'detecting unfaithful extractive summaries'),\n",
       " ('DBF model', 'Used-for', 'video multimodal fusion'),\n",
       " ('CrossSum', 'Used-for', 'cross-lingual summarization'),\n",
       " ('LaSE', 'Used-for', 'evaluating model-generated summaries'),\n",
       " ('LaSE', 'Compare', 'ROUGE'),\n",
       " ('MAS', 'Used-for', 'multimodal abstractive summarization'),\n",
       " ('Multi-DYLE', 'Used-for', 'explainable evidence extraction'),\n",
       " ('OLDS dataset', 'Used-for', 'omission detection'),\n",
       " ('ExplainMeetSum', 'Used-for', 'meeting summarization'),\n",
       " ('MeetingQA', 'Used-for', 'extractive QA'),\n",
       " ('Pisces', 'Used-for', 'many-to-many summarization'),\n",
       " ('UniSumm', 'Used-for', 'few-shot summarization'),\n",
       " ('DeFacto', 'Used-for', 'improving summary factual consistency'),\n",
       " ('AlignScore', 'Used-for', 'evaluating factual consistency'),\n",
       " ('BUMP', 'Used-for', 'evaluating faithfulness metrics'),\n",
       " ('ExplainMeetSum', 'Used-for', 'explainable evidence extraction'),\n",
       " ('commonsense question answering', 'Used-for', 'decision making'),\n",
       " ('commonsense question answering', 'Evaluate-for', 'knowledge graphs'),\n",
       " ('knowledge graphs', 'Used-for', 'commonsense question answering'),\n",
       " ('commonsense question answering', 'Part-of', 'Natural Language Processing'),\n",
       " ('commonsense question answering',\n",
       "  'Compare',\n",
       "  'open-domain question answering'),\n",
       " ('knowledge graphs', 'Hyponym-Of', 'knowledge representation learning'),\n",
       " ('commonsense question answering',\n",
       "  'Used-for',\n",
       "  'real-world knowledge evaluation'),\n",
       " ('commonsense question answering', 'Evaluate-for', 'language models'),\n",
       " ('commonsense question answering',\n",
       "  'Used-for',\n",
       "  'reasoning about everyday matters'),\n",
       " ('commonsense question answering', 'Evaluate-for', 'large language models'),\n",
       " ('commonsense question answering', 'Compare', 'Table Question Answering'),\n",
       " ('commonsense question answering',\n",
       "  'Used-for',\n",
       "  'assessing factual correctness'),\n",
       " ('reasoning task', 'Used-for', 'competitive programming task'),\n",
       " ('reasoning task', 'Used-for', 'cross-prompt automated essay scoring'),\n",
       " ('reasoning task', 'Used-for', 'hierarchical text classification'),\n",
       " ('reasoning task', 'Used-for', 'commonsense causal relations'),\n",
       " ('reasoning task', 'Used-for', 'non-factoid question answering'),\n",
       " ('reasoning task', 'Used-for', 'commonsense causality'),\n",
       " ('reasoning task',\n",
       "  'Used-for',\n",
       "  'multi-document non-factoid question answering'),\n",
       " ('reasoning task', 'Used-for', 'lexical relations prediction'),\n",
       " ('reasoning task', 'Used-for', 'event relational reasoning tasks'),\n",
       " ('reasoning task', 'Used-for', 'multi-modal reasoning task'),\n",
       " ('reasoning task', 'Used-for', 'commonsense If-Then reasoning tasks'),\n",
       " ('reasoning task', 'Used-for', 'multimodal sarcasm explanation'),\n",
       " ('reasoning task', 'Used-for', 'temporal reasoning capability'),\n",
       " ('reasoning task', 'Used-for', 'abductive reasoning tasks'),\n",
       " ('reasoning task', 'Used-for', 'counterfactual reasoning tasks'),\n",
       " ('reasoning task',\n",
       "  'Used-for',\n",
       "  'conditional inference on joint textual and visual clues'),\n",
       " ('text rationale', 'Used-for', 'explainable NLP'),\n",
       " ('text rationale', 'Evaluate-for', 'factual consistency'),\n",
       " ('text rationale', 'Evaluate-for', 'rationale-label pairs'),\n",
       " ('text rationale', 'Evaluate-for', 'new information'),\n",
       " ('text rationale', 'Evaluate-for', 'human utility'),\n",
       " ('text rationale', 'Evaluate-for', 'reasoning and prediction processes'),\n",
       " ('text rationale', 'Evaluate-for', 'free-text rationales'),\n",
       " ('text rationale', 'Evaluate-for', 'chain-of-thought'),\n",
       " ('text rationale', 'Evaluate-for', \"model's reasoning\"),\n",
       " ('summarization evaluation', 'Part-of', 'Human evaluation'),\n",
       " ('summarization evaluation', 'Part-of', 'Automatic evaluation'),\n",
       " ('summarization evaluation', 'Evaluate-for', 'Cross-lingual summarization'),\n",
       " ('summarization evaluation', 'Evaluate-for', 'Abstractive summarization'),\n",
       " ('summarization evaluation', 'Evaluate-for', 'Multimodal summarization'),\n",
       " ('summarization evaluation', 'Evaluate-for', 'Dialogue summarization'),\n",
       " ('summarization evaluation',\n",
       "  'Evaluate-for',\n",
       "  'Document-level text simplification'),\n",
       " ('Human evaluation', 'Evaluate-for', 'summarization evaluation'),\n",
       " ('Automatic evaluation', 'Evaluate-for', 'summarization evaluation'),\n",
       " ('summarization evaluation', 'Used-for', 'Assessing factual consistency'),\n",
       " ('question answering qa', 'Part-of', 'factual consistency evaluation'),\n",
       " ('WeCheck', 'Used-for', 'factual consistency evaluation'),\n",
       " ('question answering qa', 'Part-of', 'semantic parsing'),\n",
       " ('question answering qa', 'Part-of', 'instruction following'),\n",
       " ('LexSym', 'Used-for', 'compositional inductive bias'),\n",
       " ('question answering qa', 'Used-for', 'open-domain question answering'),\n",
       " ('modular retriever', 'Used-for', 'open-domain question answering'),\n",
       " ('Pangu', 'Used-for', 'knowledge base question answering'),\n",
       " ('DupMAE', 'Used-for', 'retrieval tasks'),\n",
       " ('FAME', 'Used-for', 'faithful reasoning steps'),\n",
       " ('question answering qa', 'Part-of', 'multi-document downstream tasks'),\n",
       " ('QAmden', 'Used-for', 'multi-document tasks'),\n",
       " ('MITQA', 'Used-for', 'TextTableQA'),\n",
       " ('RGCN-RCI', 'Used-for', 'Table Question Answering'),\n",
       " ('question answering qa', 'Part-of', 'commonsense question answering'),\n",
       " ('DHLK', 'Used-for', 'commonsense question answering'),\n",
       " ('AmbigPrompt', 'Used-for', 'answering ambiguous questions'),\n",
       " ('PlugD', 'Used-for', 'document-oriented NLP tasks'),\n",
       " ('SplitNER', 'Used-for', 'Named Entity Recognition'),\n",
       " ('question answering qa', 'Part-of', 'product question answering'),\n",
       " ('TASER', 'Used-for', 'dense retrieval tasks'),\n",
       " ('natural language inference', 'Part-of', 'natural language understanding'),\n",
       " ('natural language inference', 'Used-for', 'reducing reliance on shortcuts'),\n",
       " ('natural language inference',\n",
       "  'Evaluate-for',\n",
       "  'out-of-distribution performance'),\n",
       " ('natural language inference', 'Evaluate-for', 'in-distribution accuracy'),\n",
       " ('natural language inference', 'Hyponym-Of', 'natural language processing'),\n",
       " ('summarization dataset', 'Part-of', 'dialogue summarization'),\n",
       " ('summarization dataset', 'Part-of', 'cross-lingual summarization'),\n",
       " ('summarization dataset', 'Part-of', 'multi-document summarization'),\n",
       " ('summarization dataset', 'Part-of', 'extractive summarization'),\n",
       " ('summarization dataset', 'Part-of', 'abstractive summarization'),\n",
       " ('summarization dataset', 'Part-of', 'human evaluation'),\n",
       " ('summarization dataset', 'Part-of', 'few-shot summarization'),\n",
       " ('summarization dataset', 'Evaluate-for', 'summarization performance'),\n",
       " ('summarization dataset', 'Used-for', 'pre-training models'),\n",
       " ('summarization dataset', 'Used-for', 'fine-tuning models'),\n",
       " ('summarization dataset', 'Used-for', 'evaluation metrics development'),\n",
       " ('summarization dataset', 'Used-for', 'benchmarking models'),\n",
       " ('summarization dataset', 'Used-for', 'augmenting training data'),\n",
       " ('question answering', 'Used-for', 'factual consistency evaluation'),\n",
       " ('question answering', 'Part-of', 'open-domain question answering'),\n",
       " ('question answering', 'Used-for', 'generating useful intermediate context'),\n",
       " ('question answering', 'Used-for', 'retrieval model evaluation'),\n",
       " ('question answering', 'Used-for', 'elaboration generation'),\n",
       " ('question answering', 'Used-for', 'commonsense reasoning'),\n",
       " ('question answering', 'Used-for', 'cross-document informational relations'),\n",
       " ('question answering', 'Used-for', 'semantic representation'),\n",
       " ('question answering', 'Used-for', 'Table Question Answering (TQA)'),\n",
       " ('question answering', 'Used-for', 'temporal reasoning'),\n",
       " ('question answering', 'Used-for', 'information retrieval'),\n",
       " ('question answering', 'Used-for', 'long-form answers evaluation'),\n",
       " ('question answering',\n",
       "  'Used-for',\n",
       "  'knowledge base question answering (KBQA)'),\n",
       " ('question answering', 'Used-for', 'commonsense question answering'),\n",
       " ('question answering', 'Used-for', 'open domain question answering (ODQA)'),\n",
       " ('question answering', 'Used-for', 'multi-hop question answering'),\n",
       " ('question answering', 'Used-for', 'Table Question Answering (TableQA)'),\n",
       " ('question answering', 'Used-for', 'cross-lingual transfer'),\n",
       " ('question answering', 'Used-for', 'Answer Sentence Selection (AS2)'),\n",
       " ('question answering', 'Used-for', 'Event Extraction'),\n",
       " ('question answering', 'Used-for', 'dense retrieval models evaluation'),\n",
       " ('summarization system', 'Used-for', 'dialogue summarization'),\n",
       " ('DIONYSUS', 'Hyponym-Of', 'summarization system'),\n",
       " ('Compo', 'Used-for', 'data augmentation'),\n",
       " ('CSJ', 'Part-of', 'summarization system'),\n",
       " ('SSR', 'Part-of', 'CSJ'),\n",
       " ('QAmden', 'Hyponym-Of', 'summarization system'),\n",
       " ('ExtEval', 'Used-for', 'evaluating faithfulness'),\n",
       " ('CrossSum', 'Part-of', 'summarization system'),\n",
       " ('LaSE', 'Used-for', 'evaluating model-generated summaries'),\n",
       " ('MM-Sum', 'Part-of', 'summarization system'),\n",
       " ('RoSE', 'Part-of', 'summarization system'),\n",
       " ('GPTScore', 'Compare', 'G-Eval'),\n",
       " ('RSTformer', 'Hyponym-Of', 'summarization model'),\n",
       " ('SummAttacker', 'Used-for', 'generating adversarial samples'),\n",
       " ('SummAttacker', 'Used-for', 'data augmentation'),\n",
       " ('Emotion-Aware Pagerank', 'Used-for', 'detect emotions'),\n",
       " ('Emotion-Aware Pagerank', 'Used-for', 'summarize emotion triggers'),\n",
       " ('AlignScore', 'Used-for', 'evaluating factual consistency'),\n",
       " ('UniSumm', 'Part-of', 'few-shot summarization'),\n",
       " ('Multi-DYLE', 'Part-of', 'summarization system'),\n",
       " ('ExplainMeetSum', 'Part-of', 'summarization system'),\n",
       " ('FERRANTI', 'Used-for', 'evaluating factual error correction'),\n",
       " ('Summarization system', 'Evaluate-for', 'ROUGE scores'),\n",
       " ('Summarization system', 'Evaluate-for', 'human judgment'),\n",
       " ('Summarization system', 'Evaluate-for', 'faithfulness'),\n",
       " ('Summarization system', 'Evaluate-for', 'factual consistency'),\n",
       " ('form question answering', 'Conjunction', 'semantic parsing'),\n",
       " ('form question answering', 'Conjunction', 'instruction following'),\n",
       " ('form question answering',\n",
       "  'Conjunction',\n",
       "  'multi-document question answering'),\n",
       " ('form question answering', 'Conjunction', 'retrieval model'),\n",
       " ('form question answering', 'Conjunction', 'commonsense question answering'),\n",
       " ('form question answering', 'Conjunction', 'long-form question answering'),\n",
       " ('form question answering', 'Conjunction', 'product question answering'),\n",
       " ('form question answering', 'Conjunction', 'open domain question answering'),\n",
       " ('form question answering', 'Hyponym-Of', 'question answering'),\n",
       " ('form question answering', 'Evaluate-for', 'factual consistency'),\n",
       " ('form question answering', 'Evaluate-for', 'compositionality'),\n",
       " ('reasoning datasets', 'Part-of', 'question answering'),\n",
       " ('reasoning datasets', 'Part-of', 'semantic parsing'),\n",
       " ('reasoning datasets', 'Part-of', 'instruction following'),\n",
       " ('TRAC', 'Hyponym-Of', 'reasoning datasets'),\n",
       " ('COGS', 'Hyponym-Of', 'reasoning datasets'),\n",
       " ('SCAN', 'Hyponym-Of', 'reasoning datasets'),\n",
       " ('CLEVR-CoGenT', 'Hyponym-Of', 'reasoning datasets'),\n",
       " ('TempReason', 'Hyponym-Of', 'reasoning datasets'),\n",
       " ('LexSym', 'Used-for', 'data augmentation'),\n",
       " ('UNIEVENT', 'Used-for', 'knowledge transfer'),\n",
       " ('NatLogAttack', 'Used-for', 'adversarial attacks'),\n",
       " ('reasoning', 'Part-of', 'reasoning datasets'),\n",
       " ('text generation', 'Used-for', 'explainable recommendation'),\n",
       " ('text generation', 'Part-of', 'Open-ended Long Text Generation'),\n",
       " ('text generation', 'Used-for', 'attribute-based Controlled Text Generation'),\n",
       " ('text generation', 'Evaluate-for', 'factual consistency evaluation'),\n",
       " ('text generation', 'Used-for', 'audio-visual text generation'),\n",
       " ('text generation', 'Used-for', 'data-to-text generation'),\n",
       " ('text generation', 'Evaluate-for', 'controlled text generation'),\n",
       " ('text generation', 'Used-for', 'visual spatial description'),\n",
       " ('text generation', 'Used-for', 'emotion recognition in conversation'),\n",
       " ('text generation', 'Used-for', 'video-grounded dialogue generation'),\n",
       " ('text generation', 'Evaluate-for', 'open-domain dialogue systems'),\n",
       " ('text generation', 'Evaluate-for', 'fairness-related harms in AI systems'),\n",
       " ('text generation', 'Used-for', 'generating free-text rationales'),\n",
       " ('text generation', 'Used-for', 'factual consistency in summarization'),\n",
       " ('text generation',\n",
       "  'Evaluate-for',\n",
       "  'multi-aspect controllable text generation'),\n",
       " ('relation extraction', 'Part-of', 'information extraction'),\n",
       " ('pre-trained language models', 'Used-for', 'relation extraction'),\n",
       " ('continual relation extraction',\n",
       "  'Used-for',\n",
       "  'learning constantly emerging relations'),\n",
       " ('biomedical relation extraction',\n",
       "  'Used-for',\n",
       "  'multi-class classification task'),\n",
       " ('Open Information Extraction', 'Used-for', 'pipelines of various NLP tasks'),\n",
       " ('Open Information Extraction', 'Part-of', 'information extraction'),\n",
       " ('document-level relation extraction', 'Part-of', 'relation extraction'),\n",
       " ('Event Argument Extraction', 'Used-for', 'improving model generalizability'),\n",
       " ('multimodal relation extraction',\n",
       "  'Used-for',\n",
       "  'identifying semantic relationships between entities'),\n",
       " ('relation extraction', 'Used-for', 'acquisition of relational facts'),\n",
       " ('dialogue system', 'Part-of', 'chatbot'),\n",
       " ('open-domain dialogue system', 'Hyponym-Of', 'dialogue system'),\n",
       " ('Task-Oriented Dialogue System', 'Hyponym-Of', 'dialogue system'),\n",
       " ('SafeConv', 'Used-for', 'conversational safety research'),\n",
       " ('DIONYSUS', 'Used-for', 'dialogue summarization'),\n",
       " ('MoralDial', 'Used-for', 'moral dialogue system training'),\n",
       " ('retrieval-based dialogue system', 'Hyponym-Of', 'dialogue system'),\n",
       " ('multi-label intent detection', 'Used-for', 'Task-Oriented Dialogue System'),\n",
       " ('ACCENT', 'Evaluate-for', 'event commonsense evaluation'),\n",
       " ('mBART', 'Used-for', 'cross-lingual transfer'),\n",
       " ('T5', 'Used-for', 'cross-lingual transfer'),\n",
       " ('NEUPSL DSI', 'Used-for', 'dialog structure induction'),\n",
       " ('ASAP', 'Used-for', 'user satisfaction estimation'),\n",
       " ('MAKER', 'Used-for', 'knowledge retrieval'),\n",
       " ('RADE', 'Used-for', 'dialogue evaluation'),\n",
       " ('CMCF-SRNet', 'Used-for', 'emotion recognition in conversation'),\n",
       " ('fMRI2text', 'Used-for', 'brain-computer interface'),\n",
       " ('SDDS', 'Used-for', 'dialogue summarization'),\n",
       " ('OLDS dataset', 'Used-for', 'omission detection'),\n",
       " ('LiveChat', 'Used-for', 'live open-domain scenario analysis'),\n",
       " ('relation extraction docre',\n",
       "  'Evaluate-for',\n",
       "  'document-level relation extraction'),\n",
       " ('relation extraction docre', 'Part-of', 'Universal Information Extraction'),\n",
       " ('relation extraction docre', 'Used-for', 'knowledge graph construction'),\n",
       " ('relation extraction docre', 'Compare', 'multilingual relation extraction'),\n",
       " ('relation extraction docre', 'Used-for', 'multimodal relation extraction'),\n",
       " ('relation extraction docre',\n",
       "  'Is-a-Prerequisite-of',\n",
       "  'event temporal relation extraction'),\n",
       " ('relation extraction docre',\n",
       "  'Used-for',\n",
       "  'event detection and event-relation extraction tasks')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample data\n",
    "data = json.load(open('I:/11_DFKI_Hiwi/Work/01_Code/Graphusion/outputs/sample/concept_abstracts_sample.json', 'r'))\n",
    "relation_types = json.load(open('I:/11_DFKI_Hiwi/Work/01_Code/Graphusion/inputs/relation_types.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your model (ensure OPENAI_API_KEY is set)\n",
    "from src.models import KnowledgeGraphLLM\n",
    "model = KnowledgeGraphLLM(model_name=\"gpt-4o\", max_tokens=10000, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Configuration for the fusion process\n",
    "config = {\n",
    "    \"max_input_char\": 10000,  # Maximum characters from abstracts to include\n",
    "    # You could add other keys like \"refined_concepts_file\" or \"annotated_graph_file\" if needed.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fused triples path\n",
    "fused_triples_path = \"outputs/sample/original_prompt/fused_triples_sample.json\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KGRag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
