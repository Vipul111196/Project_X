{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 281 candidate triples\n"
     ]
    }
   ],
   "source": [
    "# Load relation definitions (adjust the file path as needed)\n",
    "with open(\"inputs/relation_types.json\", \"r\") as f:\n",
    "    relation_def = json.load(f)\n",
    "\n",
    "# Create a mapping from relation type to id\n",
    "relation_2_id = {rel: idx for idx, rel in enumerate(list(relation_def.keys()))}\n",
    "\n",
    "# Load candidate triples from your candidate file (output from step 2)\n",
    "candidate_triples = []\n",
    "input_file = \"outputs/sample/triples_sample.json\"  # adjust as necessary\n",
    "with open(input_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        t = json.loads(line)\n",
    "        candidate_triples.append((t['s'], t['p'], t['o']))\n",
    "\n",
    "print(f\"Loaded {len(candidate_triples)} candidate triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural language explanation', 'Evaluate-for', 'model reasoning'),\n",
       " ('natural language explanation',\n",
       "  'Evaluate-for',\n",
       "  'classification performance'),\n",
       " ('natural language explanation', 'Used-for', 'improving classification'),\n",
       " ('natural language explanation', 'Used-for', 'justifying predictions'),\n",
       " ('natural language explanation', 'Evaluate-for', 'inconsistencies detection'),\n",
       " ('natural language explanation', 'Evaluate-for', 'gender-fairness'),\n",
       " ('natural language explanation', 'Evaluate-for', 'ambiguity resolution'),\n",
       " ('natural language explanation', 'Part-of', 'natural language processing'),\n",
       " ('natural language explanation', 'Hyponym-Of', 'text explanation'),\n",
       " ('natural language explanation', 'Compare', 'text-to-image disambiguation'),\n",
       " ('natural language explanation',\n",
       "  'Used-for',\n",
       "  'enhancing language representation'),\n",
       " ('natural language explanation', 'Used-for', 'guiding model reasoning'),\n",
       " ('event relation', 'Used-for', 'event detection'),\n",
       " ('event detection', 'Used-for', 'biographical event detection'),\n",
       " ('event relation', 'Used-for', 'document-level relation extraction'),\n",
       " ('event relation', 'Used-for', 'discourse analysis'),\n",
       " ('event detection', 'Used-for', 'clinical event extraction'),\n",
       " ('event detection', 'Part-of', 'event extraction'),\n",
       " ('document-level relation extraction', 'Part-of', 'event extraction'),\n",
       " ('biographical event detection', 'Part-of', 'event extraction'),\n",
       " ('clinical event extraction', 'Part-of', 'event extraction'),\n",
       " ('event extraction', 'Used-for', 'knowledge graph construction'),\n",
       " ('shot learning', 'Hyponym-Of', 'zero-shot learning'),\n",
       " ('zero-shot learning', 'Part-of', 'in-context learning'),\n",
       " ('Perplexity Selection (Perplection)',\n",
       "  'Used-for',\n",
       "  'zero-shot text classification'),\n",
       " ('Hypernetworks for INstruction Tuning (HINT)',\n",
       "  'Used-for',\n",
       "  'enhancing zero-shot learning performance'),\n",
       " ('PESCO', 'Used-for', 'improving zero-shot text classification'),\n",
       " ('IDRISI-RA', 'Evaluate-for', 'zero-shot learning in low resource languages'),\n",
       " ('in-context learning',\n",
       "  'Is-a-Prerequisite-of',\n",
       "  'effective few-shot learning'),\n",
       " ('large language models', 'Evaluate-for', 'in-context learning performance'),\n",
       " ('multi-task learning',\n",
       "  'Used-for',\n",
       "  'enhancing conversational agent skills in zero-shot contexts'),\n",
       " ('argument extraction', 'Used-for', 'attribute extraction'),\n",
       " ('argument extraction', 'Part-of', 'Event Argument Extraction (EAE)'),\n",
       " ('argument extraction', 'Evaluate-for', 'model generalizability'),\n",
       " ('Event Argument Extraction (EAE)', 'Part-of', 'event extraction'),\n",
       " ('Event Argument Extraction (EAE)',\n",
       "  'Evaluate-for',\n",
       "  'document-level extraction'),\n",
       " ('Event Argument Extraction (EAE)',\n",
       "  'Is-a-Prerequisite-of',\n",
       "  'document-level multi-event extraction'),\n",
       " ('Event Argument Extraction (EAE)',\n",
       "  'Used-for',\n",
       "  'identifying event arguments'),\n",
       " ('document-level extraction', 'Compare', 'sentence-level extraction'),\n",
       " ('document-level extraction',\n",
       "  'Evaluate-for',\n",
       "  'handling long-range dependencies'),\n",
       " ('AMPERE', 'Used-for', 'generation-based Event Argument Extraction'),\n",
       " ('AMPERE', 'Evaluate-for', 'improving generation'),\n",
       " ('TAGPRIME', 'Used-for', 'relational structure extraction'),\n",
       " ('TAGPRIME', 'Evaluate-for', 'multiple NLP tasks'),\n",
       " ('DICE', 'Used-for', 'clinical event extraction'),\n",
       " ('DICE', 'Evaluate-for', 'news domain event extraction'),\n",
       " ('TBO', 'Used-for', 'offensive language identification'),\n",
       " ('TBO', 'Evaluate-for', 'comparing model performance'),\n",
       " ('QGA-EE', 'Used-for', 'event extraction'),\n",
       " ('DIONYSUS', 'Used-for', 'summarizing dialogues'),\n",
       " ('Compo', 'Used-for', 'generating diverse conversation-summary pairs'),\n",
       " ('CSJ', 'Used-for', 'cross-lingual scientific summarization'),\n",
       " ('SSR', 'Used-for', 'cross-lingual simplified science summaries'),\n",
       " ('QAmden', 'Used-for', 'multi-document tasks'),\n",
       " ('QAmden', 'Used-for', 'multi-document summarization'),\n",
       " ('QAmden', 'Used-for', 'query-focused summarization'),\n",
       " ('QAmden', 'Used-for', 'multi-document QA'),\n",
       " ('ExtEval', 'Used-for', 'detecting unfaithful extractive summaries'),\n",
       " ('DBF model', 'Used-for', 'video multimodal fusion'),\n",
       " ('CrossSum', 'Used-for', 'cross-lingual summarization'),\n",
       " ('LaSE', 'Used-for', 'evaluating model-generated summaries'),\n",
       " ('LaSE', 'Compare', 'ROUGE'),\n",
       " ('MAS', 'Used-for', 'multimodal abstractive summarization'),\n",
       " ('Multi-DYLE', 'Used-for', 'explainable evidence extraction'),\n",
       " ('OLDS dataset', 'Used-for', 'omission detection'),\n",
       " ('ExplainMeetSum', 'Used-for', 'meeting summarization'),\n",
       " ('MeetingQA', 'Used-for', 'extractive QA'),\n",
       " ('Pisces', 'Used-for', 'many-to-many summarization'),\n",
       " ('UniSumm', 'Used-for', 'few-shot summarization'),\n",
       " ('DeFacto', 'Used-for', 'improving summary factual consistency'),\n",
       " ('AlignScore', 'Used-for', 'evaluating factual consistency'),\n",
       " ('BUMP', 'Used-for', 'evaluating faithfulness metrics'),\n",
       " ('ExplainMeetSum', 'Used-for', 'explainable evidence extraction'),\n",
       " ('commonsense question answering', 'Used-for', 'decision making'),\n",
       " ('commonsense question answering', 'Evaluate-for', 'knowledge graphs'),\n",
       " ('knowledge graphs', 'Used-for', 'commonsense question answering'),\n",
       " ('commonsense question answering', 'Part-of', 'Natural Language Processing'),\n",
       " ('commonsense question answering',\n",
       "  'Compare',\n",
       "  'open-domain question answering'),\n",
       " ('knowledge graphs', 'Hyponym-Of', 'knowledge representation learning'),\n",
       " ('commonsense question answering',\n",
       "  'Used-for',\n",
       "  'real-world knowledge evaluation'),\n",
       " ('commonsense question answering', 'Evaluate-for', 'language models'),\n",
       " ('commonsense question answering',\n",
       "  'Used-for',\n",
       "  'reasoning about everyday matters'),\n",
       " ('commonsense question answering', 'Evaluate-for', 'large language models'),\n",
       " ('commonsense question answering', 'Compare', 'Table Question Answering'),\n",
       " ('commonsense question answering',\n",
       "  'Used-for',\n",
       "  'assessing factual correctness'),\n",
       " ('reasoning task', 'Used-for', 'competitive programming task'),\n",
       " ('reasoning task', 'Used-for', 'cross-prompt automated essay scoring'),\n",
       " ('reasoning task', 'Used-for', 'hierarchical text classification'),\n",
       " ('reasoning task', 'Used-for', 'commonsense causal relations'),\n",
       " ('reasoning task', 'Used-for', 'non-factoid question answering'),\n",
       " ('reasoning task', 'Used-for', 'commonsense causality'),\n",
       " ('reasoning task',\n",
       "  'Used-for',\n",
       "  'multi-document non-factoid question answering'),\n",
       " ('reasoning task', 'Used-for', 'lexical relations prediction'),\n",
       " ('reasoning task', 'Used-for', 'event relational reasoning tasks'),\n",
       " ('reasoning task', 'Used-for', 'multi-modal reasoning task'),\n",
       " ('reasoning task', 'Used-for', 'commonsense If-Then reasoning tasks'),\n",
       " ('reasoning task', 'Used-for', 'multimodal sarcasm explanation'),\n",
       " ('reasoning task', 'Used-for', 'temporal reasoning capability'),\n",
       " ('reasoning task', 'Used-for', 'abductive reasoning tasks'),\n",
       " ('reasoning task', 'Used-for', 'counterfactual reasoning tasks'),\n",
       " ('reasoning task',\n",
       "  'Used-for',\n",
       "  'conditional inference on joint textual and visual clues'),\n",
       " ('text rationale', 'Used-for', 'explainable NLP'),\n",
       " ('text rationale', 'Evaluate-for', 'factual consistency'),\n",
       " ('text rationale', 'Evaluate-for', 'rationale-label pairs'),\n",
       " ('text rationale', 'Evaluate-for', 'new information'),\n",
       " ('text rationale', 'Evaluate-for', 'human utility'),\n",
       " ('text rationale', 'Evaluate-for', 'reasoning and prediction processes'),\n",
       " ('text rationale', 'Evaluate-for', 'free-text rationales'),\n",
       " ('text rationale', 'Evaluate-for', 'chain-of-thought'),\n",
       " ('text rationale', 'Evaluate-for', \"model's reasoning\"),\n",
       " ('summarization evaluation', 'Part-of', 'Human evaluation'),\n",
       " ('summarization evaluation', 'Part-of', 'Automatic evaluation'),\n",
       " ('summarization evaluation', 'Evaluate-for', 'Cross-lingual summarization'),\n",
       " ('summarization evaluation', 'Evaluate-for', 'Abstractive summarization'),\n",
       " ('summarization evaluation', 'Evaluate-for', 'Multimodal summarization'),\n",
       " ('summarization evaluation', 'Evaluate-for', 'Dialogue summarization'),\n",
       " ('summarization evaluation',\n",
       "  'Evaluate-for',\n",
       "  'Document-level text simplification'),\n",
       " ('Human evaluation', 'Evaluate-for', 'summarization evaluation'),\n",
       " ('Automatic evaluation', 'Evaluate-for', 'summarization evaluation'),\n",
       " ('summarization evaluation', 'Used-for', 'Assessing factual consistency'),\n",
       " ('question answering qa', 'Part-of', 'factual consistency evaluation'),\n",
       " ('WeCheck', 'Used-for', 'factual consistency evaluation'),\n",
       " ('question answering qa', 'Part-of', 'semantic parsing'),\n",
       " ('question answering qa', 'Part-of', 'instruction following'),\n",
       " ('LexSym', 'Used-for', 'compositional inductive bias'),\n",
       " ('question answering qa', 'Used-for', 'open-domain question answering'),\n",
       " ('modular retriever', 'Used-for', 'open-domain question answering'),\n",
       " ('Pangu', 'Used-for', 'knowledge base question answering'),\n",
       " ('DupMAE', 'Used-for', 'retrieval tasks'),\n",
       " ('FAME', 'Used-for', 'faithful reasoning steps'),\n",
       " ('question answering qa', 'Part-of', 'multi-document downstream tasks'),\n",
       " ('QAmden', 'Used-for', 'multi-document tasks'),\n",
       " ('MITQA', 'Used-for', 'TextTableQA'),\n",
       " ('RGCN-RCI', 'Used-for', 'Table Question Answering'),\n",
       " ('question answering qa', 'Part-of', 'commonsense question answering'),\n",
       " ('DHLK', 'Used-for', 'commonsense question answering'),\n",
       " ('AmbigPrompt', 'Used-for', 'answering ambiguous questions'),\n",
       " ('PlugD', 'Used-for', 'document-oriented NLP tasks'),\n",
       " ('SplitNER', 'Used-for', 'Named Entity Recognition'),\n",
       " ('question answering qa', 'Part-of', 'product question answering'),\n",
       " ('TASER', 'Used-for', 'dense retrieval tasks'),\n",
       " ('natural language inference', 'Part-of', 'natural language understanding'),\n",
       " ('natural language inference', 'Used-for', 'reducing reliance on shortcuts'),\n",
       " ('natural language inference',\n",
       "  'Evaluate-for',\n",
       "  'out-of-distribution performance'),\n",
       " ('natural language inference', 'Evaluate-for', 'in-distribution accuracy'),\n",
       " ('natural language inference', 'Hyponym-Of', 'natural language processing'),\n",
       " ('summarization dataset', 'Part-of', 'dialogue summarization'),\n",
       " ('summarization dataset', 'Part-of', 'cross-lingual summarization'),\n",
       " ('summarization dataset', 'Part-of', 'multi-document summarization'),\n",
       " ('summarization dataset', 'Part-of', 'extractive summarization'),\n",
       " ('summarization dataset', 'Part-of', 'abstractive summarization'),\n",
       " ('summarization dataset', 'Part-of', 'human evaluation'),\n",
       " ('summarization dataset', 'Part-of', 'few-shot summarization'),\n",
       " ('summarization dataset', 'Evaluate-for', 'summarization performance'),\n",
       " ('summarization dataset', 'Used-for', 'pre-training models'),\n",
       " ('summarization dataset', 'Used-for', 'fine-tuning models'),\n",
       " ('summarization dataset', 'Used-for', 'evaluation metrics development'),\n",
       " ('summarization dataset', 'Used-for', 'benchmarking models'),\n",
       " ('summarization dataset', 'Used-for', 'augmenting training data'),\n",
       " ('question answering', 'Used-for', 'factual consistency evaluation'),\n",
       " ('question answering', 'Part-of', 'open-domain question answering'),\n",
       " ('question answering', 'Used-for', 'generating useful intermediate context'),\n",
       " ('question answering', 'Used-for', 'retrieval model evaluation'),\n",
       " ('question answering', 'Used-for', 'elaboration generation'),\n",
       " ('question answering', 'Used-for', 'commonsense reasoning'),\n",
       " ('question answering', 'Used-for', 'cross-document informational relations'),\n",
       " ('question answering', 'Used-for', 'semantic representation'),\n",
       " ('question answering', 'Used-for', 'Table Question Answering (TQA)'),\n",
       " ('question answering', 'Used-for', 'temporal reasoning'),\n",
       " ('question answering', 'Used-for', 'information retrieval'),\n",
       " ('question answering', 'Used-for', 'long-form answers evaluation'),\n",
       " ('question answering',\n",
       "  'Used-for',\n",
       "  'knowledge base question answering (KBQA)'),\n",
       " ('question answering', 'Used-for', 'commonsense question answering'),\n",
       " ('question answering', 'Used-for', 'open domain question answering (ODQA)'),\n",
       " ('question answering', 'Used-for', 'multi-hop question answering'),\n",
       " ('question answering', 'Used-for', 'Table Question Answering (TableQA)'),\n",
       " ('question answering', 'Used-for', 'cross-lingual transfer'),\n",
       " ('question answering', 'Used-for', 'Answer Sentence Selection (AS2)'),\n",
       " ('question answering', 'Used-for', 'Event Extraction'),\n",
       " ('question answering', 'Used-for', 'dense retrieval models evaluation'),\n",
       " ('summarization system', 'Used-for', 'dialogue summarization'),\n",
       " ('DIONYSUS', 'Hyponym-Of', 'summarization system'),\n",
       " ('Compo', 'Used-for', 'data augmentation'),\n",
       " ('CSJ', 'Part-of', 'summarization system'),\n",
       " ('SSR', 'Part-of', 'CSJ'),\n",
       " ('QAmden', 'Hyponym-Of', 'summarization system'),\n",
       " ('ExtEval', 'Used-for', 'evaluating faithfulness'),\n",
       " ('CrossSum', 'Part-of', 'summarization system'),\n",
       " ('LaSE', 'Used-for', 'evaluating model-generated summaries'),\n",
       " ('MM-Sum', 'Part-of', 'summarization system'),\n",
       " ('RoSE', 'Part-of', 'summarization system'),\n",
       " ('GPTScore', 'Compare', 'G-Eval'),\n",
       " ('RSTformer', 'Hyponym-Of', 'summarization model'),\n",
       " ('SummAttacker', 'Used-for', 'generating adversarial samples'),\n",
       " ('SummAttacker', 'Used-for', 'data augmentation'),\n",
       " ('Emotion-Aware Pagerank', 'Used-for', 'detect emotions'),\n",
       " ('Emotion-Aware Pagerank', 'Used-for', 'summarize emotion triggers'),\n",
       " ('AlignScore', 'Used-for', 'evaluating factual consistency'),\n",
       " ('UniSumm', 'Part-of', 'few-shot summarization'),\n",
       " ('Multi-DYLE', 'Part-of', 'summarization system'),\n",
       " ('ExplainMeetSum', 'Part-of', 'summarization system'),\n",
       " ('FERRANTI', 'Used-for', 'evaluating factual error correction'),\n",
       " ('Summarization system', 'Evaluate-for', 'ROUGE scores'),\n",
       " ('Summarization system', 'Evaluate-for', 'human judgment'),\n",
       " ('Summarization system', 'Evaluate-for', 'faithfulness'),\n",
       " ('Summarization system', 'Evaluate-for', 'factual consistency'),\n",
       " ('form question answering', 'Conjunction', 'semantic parsing'),\n",
       " ('form question answering', 'Conjunction', 'instruction following'),\n",
       " ('form question answering',\n",
       "  'Conjunction',\n",
       "  'multi-document question answering'),\n",
       " ('form question answering', 'Conjunction', 'retrieval model'),\n",
       " ('form question answering', 'Conjunction', 'commonsense question answering'),\n",
       " ('form question answering', 'Conjunction', 'long-form question answering'),\n",
       " ('form question answering', 'Conjunction', 'product question answering'),\n",
       " ('form question answering', 'Conjunction', 'open domain question answering'),\n",
       " ('form question answering', 'Hyponym-Of', 'question answering'),\n",
       " ('form question answering', 'Evaluate-for', 'factual consistency'),\n",
       " ('form question answering', 'Evaluate-for', 'compositionality'),\n",
       " ('reasoning datasets', 'Part-of', 'question answering'),\n",
       " ('reasoning datasets', 'Part-of', 'semantic parsing'),\n",
       " ('reasoning datasets', 'Part-of', 'instruction following'),\n",
       " ('TRAC', 'Hyponym-Of', 'reasoning datasets'),\n",
       " ('COGS', 'Hyponym-Of', 'reasoning datasets'),\n",
       " ('SCAN', 'Hyponym-Of', 'reasoning datasets'),\n",
       " ('CLEVR-CoGenT', 'Hyponym-Of', 'reasoning datasets'),\n",
       " ('TempReason', 'Hyponym-Of', 'reasoning datasets'),\n",
       " ('LexSym', 'Used-for', 'data augmentation'),\n",
       " ('UNIEVENT', 'Used-for', 'knowledge transfer'),\n",
       " ('NatLogAttack', 'Used-for', 'adversarial attacks'),\n",
       " ('reasoning', 'Part-of', 'reasoning datasets'),\n",
       " ('text generation', 'Used-for', 'explainable recommendation'),\n",
       " ('text generation', 'Part-of', 'Open-ended Long Text Generation'),\n",
       " ('text generation', 'Used-for', 'attribute-based Controlled Text Generation'),\n",
       " ('text generation', 'Evaluate-for', 'factual consistency evaluation'),\n",
       " ('text generation', 'Used-for', 'audio-visual text generation'),\n",
       " ('text generation', 'Used-for', 'data-to-text generation'),\n",
       " ('text generation', 'Evaluate-for', 'controlled text generation'),\n",
       " ('text generation', 'Used-for', 'visual spatial description'),\n",
       " ('text generation', 'Used-for', 'emotion recognition in conversation'),\n",
       " ('text generation', 'Used-for', 'video-grounded dialogue generation'),\n",
       " ('text generation', 'Evaluate-for', 'open-domain dialogue systems'),\n",
       " ('text generation', 'Evaluate-for', 'fairness-related harms in AI systems'),\n",
       " ('text generation', 'Used-for', 'generating free-text rationales'),\n",
       " ('text generation', 'Used-for', 'factual consistency in summarization'),\n",
       " ('text generation',\n",
       "  'Evaluate-for',\n",
       "  'multi-aspect controllable text generation'),\n",
       " ('relation extraction', 'Part-of', 'information extraction'),\n",
       " ('pre-trained language models', 'Used-for', 'relation extraction'),\n",
       " ('continual relation extraction',\n",
       "  'Used-for',\n",
       "  'learning constantly emerging relations'),\n",
       " ('biomedical relation extraction',\n",
       "  'Used-for',\n",
       "  'multi-class classification task'),\n",
       " ('Open Information Extraction', 'Used-for', 'pipelines of various NLP tasks'),\n",
       " ('Open Information Extraction', 'Part-of', 'information extraction'),\n",
       " ('document-level relation extraction', 'Part-of', 'relation extraction'),\n",
       " ('Event Argument Extraction', 'Used-for', 'improving model generalizability'),\n",
       " ('multimodal relation extraction',\n",
       "  'Used-for',\n",
       "  'identifying semantic relationships between entities'),\n",
       " ('relation extraction', 'Used-for', 'acquisition of relational facts'),\n",
       " ('dialogue system', 'Part-of', 'chatbot'),\n",
       " ('open-domain dialogue system', 'Hyponym-Of', 'dialogue system'),\n",
       " ('Task-Oriented Dialogue System', 'Hyponym-Of', 'dialogue system'),\n",
       " ('SafeConv', 'Used-for', 'conversational safety research'),\n",
       " ('DIONYSUS', 'Used-for', 'dialogue summarization'),\n",
       " ('MoralDial', 'Used-for', 'moral dialogue system training'),\n",
       " ('retrieval-based dialogue system', 'Hyponym-Of', 'dialogue system'),\n",
       " ('multi-label intent detection', 'Used-for', 'Task-Oriented Dialogue System'),\n",
       " ('ACCENT', 'Evaluate-for', 'event commonsense evaluation'),\n",
       " ('mBART', 'Used-for', 'cross-lingual transfer'),\n",
       " ('T5', 'Used-for', 'cross-lingual transfer'),\n",
       " ('NEUPSL DSI', 'Used-for', 'dialog structure induction'),\n",
       " ('ASAP', 'Used-for', 'user satisfaction estimation'),\n",
       " ('MAKER', 'Used-for', 'knowledge retrieval'),\n",
       " ('RADE', 'Used-for', 'dialogue evaluation'),\n",
       " ('CMCF-SRNet', 'Used-for', 'emotion recognition in conversation'),\n",
       " ('fMRI2text', 'Used-for', 'brain-computer interface'),\n",
       " ('SDDS', 'Used-for', 'dialogue summarization'),\n",
       " ('OLDS dataset', 'Used-for', 'omission detection'),\n",
       " ('LiveChat', 'Used-for', 'live open-domain scenario analysis'),\n",
       " ('relation extraction docre',\n",
       "  'Evaluate-for',\n",
       "  'document-level relation extraction'),\n",
       " ('relation extraction docre', 'Part-of', 'Universal Information Extraction'),\n",
       " ('relation extraction docre', 'Used-for', 'knowledge graph construction'),\n",
       " ('relation extraction docre', 'Compare', 'multilingual relation extraction'),\n",
       " ('relation extraction docre', 'Used-for', 'multimodal relation extraction'),\n",
       " ('relation extraction docre',\n",
       "  'Is-a-Prerequisite-of',\n",
       "  'event temporal relation extraction'),\n",
       " ('relation extraction docre',\n",
       "  'Used-for',\n",
       "  'event detection and event-relation extraction tasks')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample data\n",
    "data = json.load(open('I:/11_DFKI_Hiwi/Work/01_Code/Graphusion/outputs/sample/concept_abstracts_sample.json', 'r'))\n",
    "relation_types = json.load(open('I:/11_DFKI_Hiwi/Work/01_Code/Graphusion/inputs/relation_types.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your model (ensure OPENAI_API_KEY is set)\n",
    "from src.models import KnowledgeGraphLLM\n",
    "model = KnowledgeGraphLLM(model_name=\"gpt-4o\", max_tokens=10000, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Configuration for the fusion process\n",
    "config = {\n",
    "    \"max_input_char\": 10000,  # Maximum characters from abstracts to include\n",
    "    # You could add other keys like \"refined_concepts_file\" or \"annotated_graph_file\" if needed.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fused triples path\n",
    "fused_triples_path = \"outputs/sample/original_prompt/fused_triples_sample.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def fuse_triples(model, candidate_triples, relation_def, data):\n",
    "    \n",
    "    fused_triples = []\n",
    "    # For each unique concept (from candidate triples), create a textual summary of its related triples\n",
    "    candidate_concepts = set(data.keys())\n",
    "\n",
    "    for concept in tqdm(list(candidate_concepts)):\n",
    "        # Create a simple string representation (list all triples involving this concept)\n",
    "        candidate_subgraph = []\n",
    "        for triple in candidate_triples:\n",
    "            if concept in triple:\n",
    "                candidate_subgraph.append(f\"({triple[0]}, {triple[1]}, {triple[2]})\")\n",
    "                \n",
    "        # Get background abstracts (if available)\n",
    "        background = \"\"\n",
    "        if concept in data:\n",
    "            background = ' --  '.join(data[concept]['abstracts'])\n",
    "        else:\n",
    "            print(f\"No background found for concept {concept}\")\n",
    "            background = \"No background information available.\"\n",
    "        \n",
    "        # Build the fusion prompt using a simple formatted string\n",
    "        prompt_template_txt = open(\"prompts/prompt_fusion.txt\").read()\n",
    "        # print(prompt_template_txt)\n",
    "        prompt_template = ChatPromptTemplate.from_template(prompt_template_txt)\n",
    "        # print('Prompt template', prompt_template)   \n",
    "        \n",
    "        prompt = prompt_template.invoke({\n",
    "            \"concept\": concept,\n",
    "            \"graph1\": candidate_subgraph,\n",
    "            \"graph2\": fused_triples,\n",
    "            \"background\": background,\n",
    "            \"relation_definitions\": '\\n'.join([f\"{k}: {v['description']}\" for k, v in relation_def.items()])\n",
    "        })\n",
    "\n",
    "        response = model.invoke(prompt)\n",
    "        print(f\"Response for concept {concept}: {response}\")    \n",
    "\n",
    "        print(\"/n /n /n\") \n",
    "\n",
    "        if response and response != \"None\":\n",
    "            try:\n",
    "                response_json = json.loads(response)\n",
    "                for triple in response_json:\n",
    "                    # Validate the relation exists in your definitions\n",
    "                    if triple['p'] in relation_def:\n",
    "                        fused_triples.append((triple['s'], triple['p'], triple['o']))\n",
    "            except Exception as e:\n",
    "                print(f\"Error fusing triples for concept {concept}: {e}\")\n",
    "        \n",
    "        fused_triples = list(set(fused_triples))\n",
    "        print(f\"Total fused triples: {len(fused_triples)}\")\n",
    "        \n",
    "    return fused_triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:06<01:59,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept text rationale: [{\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:13<02:02,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept relation extraction: [{\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:22<02:11,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept argument extraction: [{\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:38<02:56, 11.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept question answering qa: [{\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:56<03:21, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept natural language explanation: [{\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:04<02:43, 11.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept relation extraction docre: [{\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [01:14<02:26, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept summarization system: [{\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [02:01<04:31, 22.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept summarization evaluation: [{\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Human evaluation\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Automatic evaluation\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Cross-lingual summarization\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Abstractive summarization\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Multimodal summarization\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Dialogue summarization\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Document-level text simplification\"}, {\"s\": \"Human evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"Automatic evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"summarization evaluation\", \"p\": \"Used-for\", \"o\": \"Assessing factual consistency\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"document-level text simplification\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:33<04:40, 25.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept event relation: [{\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"event detection\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"discourse analysis\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Abstractive summarization\"}, {\"s\": \"Automatic evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Automatic evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Document-level text simplification\"}, {\"s\": \"summarization evaluation\", \"p\": \"Used-for\", \"o\": \"Assessing factual consistency\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Cross-lingual summarization\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Multimodal summarization\"}, {\"s\": \"Human evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Dialogue summarization\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"document-level text simplification\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [03:05<04:36, 27.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept shot learning: [{\"s\": \"shot learning\", \"p\": \"Hyponym-Of\", \"o\": \"zero-shot learning\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Abstractive summarization\"}, {\"s\": \"Automatic evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Automatic evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Document-level text simplification\"}, {\"s\": \"summarization evaluation\", \"p\": \"Used-for\", \"o\": \"Assessing factual consistency\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"discourse analysis\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Cross-lingual summarization\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Multimodal summarization\"}, {\"s\": \"Human evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Dialogue summarization\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"document-level text simplification\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"event detection\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [03:14<03:16, 21.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept natural language inference: [{\"s\": \"natural language inference\", \"p\": \"Part-of\", \"o\": \"natural language understanding\"}, {\"s\": \"natural language inference\", \"p\": \"Used-for\", \"o\": \"reducing reliance on shortcuts\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"out-of-distribution performance\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"in-distribution accuracy\"}, {\"s\": \"natural language inference\", \"p\": \"Hyponym-Of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [03:59<03:50, 28.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept text generation: [{\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"explainable recommendation\"}, {\"s\": \"text generation\", \"p\": \"Part-of\", \"o\": \"Open-ended Long Text Generation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"attribute-based Controlled Text Generation\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"audio-visual text generation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"data-to-text generation\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"controlled text generation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"visual spatial description\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"emotion recognition in conversation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"video-grounded dialogue generation\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"open-domain dialogue systems\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"fairness-related harms in AI systems\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"generating free-text rationales\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency in summarization\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"multi-aspect controllable text generation\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"natural language inference\", \"p\": \"Part-of\", \"o\": \"natural language understanding\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Abstractive summarization\"}, {\"s\": \"Automatic evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"shot learning\", \"p\": \"Hyponym-Of\", \"o\": \"zero-shot learning\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Automatic evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Document-level text simplification\"}, {\"s\": \"summarization evaluation\", \"p\": \"Used-for\", \"o\": \"Assessing factual consistency\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"discourse analysis\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Cross-lingual summarization\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"natural language inference\", \"p\": \"Used-for\", \"o\": \"reducing reliance on shortcuts\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"out-of-distribution performance\"}, {\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Multimodal summarization\"}, {\"s\": \"Human evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Dialogue summarization\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"in-distribution accuracy\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"document-level text simplification\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"event detection\"}, {\"s\": \"natural language inference\", \"p\": \"Hyponym-Of\", \"o\": \"natural language processing\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [05:11<04:54, 42.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept reasoning datasets: [{\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"question answering\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"TRAC\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"COGS\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"SCAN\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"CLEVR-CoGenT\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"TempReason\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"reasoning\", \"p\": \"Part-of\", \"o\": \"reasoning datasets\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Abstractive summarization\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"generating free-text rationales\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"summarization evaluation\", \"p\": \"Used-for\", \"o\": \"Assessing factual consistency\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"Human evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Dialogue summarization\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"controlled text generation\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"data-to-text generation\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"explainable recommendation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"attribute-based Controlled Text Generation\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"text generation\", \"p\": \"Part-of\", \"o\": \"Open-ended Long Text Generation\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency in summarization\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"audio-visual text generation\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"multi-aspect controllable text generation\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"document-level text simplification\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"event detection\"}, {\"s\": \"natural language inference\", \"p\": \"Used-for\", \"o\": \"reducing reliance on shortcuts\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"open-domain dialogue systems\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Automatic evaluation\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"out-of-distribution performance\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Multimodal summarization\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"in-distribution accuracy\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"natural language inference\", \"p\": \"Part-of\", \"o\": \"natural language understanding\"}, {\"s\": \"Automatic evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"shot learning\", \"p\": \"Hyponym-Of\", \"o\": \"zero-shot learning\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"fairness-related harms in AI systems\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Document-level text simplification\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"visual spatial description\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"discourse analysis\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"video-grounded dialogue generation\"}, {\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"emotion recognition in conversation\"}, {\"s\": \"natural language inference\", \"p\": \"Hyponym-Of\", \"o\": \"natural language processing\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [06:18<04:56, 49.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept form question answering: [{\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"semantic parsing\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"instruction following\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"multi-document question answering\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"retrieval model\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"commonsense question answering\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"long-form question answering\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"product question answering\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"open domain question answering\"}, {\"s\": \"form question answering\", \"p\": \"Hyponym-Of\", \"o\": \"question answering\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"compositionality\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Abstractive summarization\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"generating free-text rationales\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"summarization evaluation\", \"p\": \"Used-for\", \"o\": \"Assessing factual consistency\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"Human evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Dialogue summarization\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"COGS\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"controlled text generation\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"data-to-text generation\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"explainable recommendation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"attribute-based Controlled Text Generation\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"text generation\", \"p\": \"Part-of\", \"o\": \"Open-ended Long Text Generation\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency in summarization\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"audio-visual text generation\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"TempReason\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"multi-aspect controllable text generation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"document-level text simplification\"}, {\"s\": \"CLEVR-CoGenT\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"event detection\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"natural language inference\", \"p\": \"Used-for\", \"o\": \"reducing reliance on shortcuts\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"open-domain dialogue systems\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Automatic evaluation\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"TRAC\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"SCAN\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"out-of-distribution performance\"}, {\"s\": \"reasoning\", \"p\": \"Part-of\", \"o\": \"reasoning datasets\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Multimodal summarization\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"in-distribution accuracy\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"natural language inference\", \"p\": \"Part-of\", \"o\": \"natural language understanding\"}, {\"s\": \"Automatic evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"shot learning\", \"p\": \"Hyponym-Of\", \"o\": \"zero-shot learning\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"fairness-related harms in AI systems\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Document-level text simplification\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"visual spatial description\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"discourse analysis\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"video-grounded dialogue generation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"emotion recognition in conversation\"}, {\"s\": \"natural language inference\", \"p\": \"Hyponym-Of\", \"o\": \"natural language processing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [07:19<04:23, 52.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept dialogue system: [{\"s\": \"dialogue system\", \"p\": \"Part-of\", \"o\": \"chatbot\"}, {\"s\": \"open-domain dialogue system\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"Task-Oriented Dialogue System\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"retrieval-based dialogue system\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Abstractive summarization\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"instruction following\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"generating free-text rationales\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"summarization evaluation\", \"p\": \"Used-for\", \"o\": \"Assessing factual consistency\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"Human evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"commonsense question answering\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Dialogue summarization\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"COGS\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"controlled text generation\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"open domain question answering\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"data-to-text generation\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"explainable recommendation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"attribute-based Controlled Text Generation\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"semantic parsing\"}, {\"s\": \"text generation\", \"p\": \"Part-of\", \"o\": \"Open-ended Long Text Generation\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"multi-document question answering\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency in summarization\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"audio-visual text generation\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"TempReason\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"multi-aspect controllable text generation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"product question answering\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"document-level text simplification\"}, {\"s\": \"CLEVR-CoGenT\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"event detection\"}, {\"s\": \"natural language inference\", \"p\": \"Used-for\", \"o\": \"reducing reliance on shortcuts\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"open-domain dialogue systems\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"retrieval model\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"long-form question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Automatic evaluation\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"TRAC\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"SCAN\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"out-of-distribution performance\"}, {\"s\": \"reasoning\", \"p\": \"Part-of\", \"o\": \"reasoning datasets\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Multimodal summarization\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"in-distribution accuracy\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"natural language inference\", \"p\": \"Part-of\", \"o\": \"natural language understanding\"}, {\"s\": \"Automatic evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"shot learning\", \"p\": \"Hyponym-Of\", \"o\": \"zero-shot learning\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"fairness-related harms in AI systems\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Document-level text simplification\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"visual spatial description\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"discourse analysis\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"form question answering\", \"p\": \"Hyponym-Of\", \"o\": \"question answering\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"video-grounded dialogue generation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"compositionality\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"emotion recognition in conversation\"}, {\"s\": \"natural language inference\", \"p\": \"Hyponym-Of\", \"o\": \"natural language processing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [08:27<03:49, 57.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept commonsense question answering: [{\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"decision making\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"knowledge graphs\"}, {\"s\": \"knowledge graphs\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}, {\"s\": \"commonsense question answering\", \"p\": \"Part-of\", \"o\": \"Natural Language Processing\"}, {\"s\": \"commonsense question answering\", \"p\": \"Compare\", \"o\": \"open-domain question answering\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"real-world knowledge evaluation\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"language models\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"reasoning about everyday matters\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"large language models\"}, {\"s\": \"commonsense question answering\", \"p\": \"Compare\", \"o\": \"Table Question Answering\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"assessing factual correctness\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"DHLK\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"commonsense question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Abstractive summarization\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"instruction following\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"generating free-text rationales\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"summarization evaluation\", \"p\": \"Used-for\", \"o\": \"Assessing factual consistency\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"Human evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"open domain question answering\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Dialogue summarization\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"COGS\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"controlled text generation\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"semantic parsing\"}, {\"s\": \"text generation\", \"p\": \"Part-of\", \"o\": \"Open-ended Long Text Generation\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"multi-document question answering\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency in summarization\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"audio-visual text generation\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"Task-Oriented Dialogue System\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"TempReason\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"multi-aspect controllable text generation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"product question answering\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"document-level text simplification\"}, {\"s\": \"CLEVR-CoGenT\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"event detection\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"natural language inference\", \"p\": \"Used-for\", \"o\": \"reducing reliance on shortcuts\"}, {\"s\": \"dialogue system\", \"p\": \"Part-of\", \"o\": \"chatbot\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"open-domain dialogue system\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"open-domain dialogue systems\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"retrieval model\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"long-form question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Automatic evaluation\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"TRAC\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"SCAN\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"out-of-distribution performance\"}, {\"s\": \"reasoning\", \"p\": \"Part-of\", \"o\": \"reasoning datasets\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Multimodal summarization\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"in-distribution accuracy\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"natural language inference\", \"p\": \"Part-of\", \"o\": \"natural language understanding\"}, {\"s\": \"Automatic evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"shot learning\", \"p\": \"Hyponym-Of\", \"o\": \"zero-shot learning\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"fairness-related harms in AI systems\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Document-level text simplification\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"visual spatial description\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"discourse analysis\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"form question answering\", \"p\": \"Hyponym-Of\", \"o\": \"question answering\"}, {\"s\": \"retrieval-based dialogue system\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"video-grounded dialogue generation\"}, {\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"compositionality\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"emotion recognition in conversation\"}, {\"s\": \"natural language inference\", \"p\": \"Hyponym-Of\", \"o\": \"natural language processing\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"factual consistency evaluation\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [09:51<03:16, 65.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept reasoning task: [{\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"competitive programming task\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"cross-prompt automated essay scoring\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"hierarchical text classification\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"commonsense causal relations\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"non-factoid question answering\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"commonsense causality\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"multi-document non-factoid question answering\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"lexical relations prediction\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"event relational reasoning tasks\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"multi-modal reasoning task\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"commonsense If-Then reasoning tasks\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"multimodal sarcasm explanation\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"temporal reasoning capability\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"abductive reasoning tasks\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"counterfactual reasoning tasks\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"conditional inference on joint textual and visual clues\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Abstractive summarization\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"instruction following\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"generating free-text rationales\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"summarization evaluation\", \"p\": \"Used-for\", \"o\": \"Assessing factual consistency\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"decision making\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"real-world knowledge evaluation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"Human evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"commonsense question answering\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Dialogue summarization\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"COGS\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"controlled text generation\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"open domain question answering\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"data-to-text generation\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"explainable recommendation\"}, {\"s\": \"commonsense question answering\", \"p\": \"Part-of\", \"o\": \"Natural Language Processing\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"attribute-based Controlled Text Generation\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"semantic parsing\"}, {\"s\": \"text generation\", \"p\": \"Part-of\", \"o\": \"Open-ended Long Text Generation\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"multi-document question answering\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency in summarization\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"audio-visual text generation\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"assessing factual correctness\"}, {\"s\": \"Task-Oriented Dialogue System\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"TempReason\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"multi-aspect controllable text generation\"}, {\"s\": \"commonsense question answering\", \"p\": \"Compare\", \"o\": \"open-domain question answering\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"product question answering\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"document-level text simplification\"}, {\"s\": \"CLEVR-CoGenT\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"commonsense question answering\", \"p\": \"Compare\", \"o\": \"Table Question Answering\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"event detection\"}, {\"s\": \"natural language inference\", \"p\": \"Used-for\", \"o\": \"reducing reliance on shortcuts\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"dialogue system\", \"p\": \"Part-of\", \"o\": \"chatbot\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"knowledge graphs\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}, {\"s\": \"open-domain dialogue system\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"open-domain dialogue systems\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"knowledge graphs\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"retrieval model\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"long-form question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Automatic evaluation\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"TRAC\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"SCAN\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"out-of-distribution performance\"}, {\"s\": \"reasoning\", \"p\": \"Part-of\", \"o\": \"reasoning datasets\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Multimodal summarization\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"in-distribution accuracy\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"language models\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"natural language inference\", \"p\": \"Part-of\", \"o\": \"natural language understanding\"}, {\"s\": \"Automatic evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"shot learning\", \"p\": \"Hyponym-Of\", \"o\": \"zero-shot learning\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"fairness-related harms in AI systems\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Document-level text simplification\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"visual spatial description\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"discourse analysis\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"large language models\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"form question answering\", \"p\": \"Hyponym-Of\", \"o\": \"question answering\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"retrieval-based dialogue system\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"video-grounded dialogue generation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"reasoning about everyday matters\"}, {\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"compositionality\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"emotion recognition in conversation\"}, {\"s\": \"natural language inference\", \"p\": \"Hyponym-Of\", \"o\": \"natural language processing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"DHLK\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [11:11<02:19, 69.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept summarization dataset: [{\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"dialogue summarization\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"multi-document summarization\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"extractive summarization\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"abstractive summarization\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"human evaluation\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"few-shot summarization\"}, {\"s\": \"summarization dataset\", \"p\": \"Evaluate-for\", \"o\": \"summarization performance\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"pre-training models\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"fine-tuning models\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"evaluation metrics development\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"benchmarking models\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"augmenting training data\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Abstractive summarization\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"instruction following\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"generating free-text rationales\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"summarization evaluation\", \"p\": \"Used-for\", \"o\": \"Assessing factual consistency\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"commonsense If-Then reasoning tasks\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"decision making\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"real-world knowledge evaluation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"conditional inference on joint textual and visual clues\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"Human evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"commonsense question answering\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Dialogue summarization\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"multi-document non-factoid question answering\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"counterfactual reasoning tasks\"}, {\"s\": \"COGS\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"controlled text generation\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"open domain question answering\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"data-to-text generation\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"commonsense causality\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"explainable recommendation\"}, {\"s\": \"commonsense question answering\", \"p\": \"Part-of\", \"o\": \"Natural Language Processing\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"attribute-based Controlled Text Generation\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"semantic parsing\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"abductive reasoning tasks\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"cross-prompt automated essay scoring\"}, {\"s\": \"text generation\", \"p\": \"Part-of\", \"o\": \"Open-ended Long Text Generation\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"multi-document question answering\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency in summarization\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"audio-visual text generation\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"multimodal sarcasm explanation\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"assessing factual correctness\"}, {\"s\": \"Task-Oriented Dialogue System\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"TempReason\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"multi-aspect controllable text generation\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"event relational reasoning tasks\"}, {\"s\": \"commonsense question answering\", \"p\": \"Compare\", \"o\": \"open-domain question answering\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"temporal reasoning capability\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"product question answering\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"document-level text simplification\"}, {\"s\": \"CLEVR-CoGenT\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"commonsense question answering\", \"p\": \"Compare\", \"o\": \"Table Question Answering\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"event detection\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"lexical relations prediction\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"natural language inference\", \"p\": \"Used-for\", \"o\": \"reducing reliance on shortcuts\"}, {\"s\": \"dialogue system\", \"p\": \"Part-of\", \"o\": \"chatbot\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"knowledge graphs\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}, {\"s\": \"open-domain dialogue system\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"competitive programming task\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"open-domain dialogue systems\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"knowledge graphs\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"non-factoid question answering\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"retrieval model\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"long-form question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Automatic evaluation\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"multi-modal reasoning task\"}, {\"s\": \"TRAC\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"SCAN\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"out-of-distribution performance\"}, {\"s\": \"reasoning\", \"p\": \"Part-of\", \"o\": \"reasoning datasets\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Multimodal summarization\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"in-distribution accuracy\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"language models\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"natural language inference\", \"p\": \"Part-of\", \"o\": \"natural language understanding\"}, {\"s\": \"Automatic evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"shot learning\", \"p\": \"Hyponym-Of\", \"o\": \"zero-shot learning\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"fairness-related harms in AI systems\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Document-level text simplification\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"visual spatial description\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"hierarchical text classification\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"discourse analysis\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"large language models\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"form question answering\", \"p\": \"Hyponym-Of\", \"o\": \"question answering\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"retrieval-based dialogue system\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"video-grounded dialogue generation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"reasoning about everyday matters\"}, {\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"compositionality\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"emotion recognition in conversation\"}, {\"s\": \"natural language inference\", \"p\": \"Hyponym-Of\", \"o\": \"natural language processing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"commonsense causal relations\"}, {\"s\": \"DHLK\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [12:53<01:19, 79.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept summarization model: [{\"s\": \"RSTformer\", \"p\": \"Hyponym-Of\", \"o\": \"summarization model\"}, {\"s\": \"summarization dataset\", \"p\": \"Evaluate-for\", \"o\": \"summarization performance\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Abstractive summarization\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"instruction following\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"generating free-text rationales\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"extractive summarization\"}, {\"s\": \"summarization evaluation\", \"p\": \"Used-for\", \"o\": \"Assessing factual consistency\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"commonsense If-Then reasoning tasks\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"decision making\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"abstractive summarization\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"real-world knowledge evaluation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"conditional inference on joint textual and visual clues\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"Human evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"commonsense question answering\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Dialogue summarization\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"multi-document non-factoid question answering\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"counterfactual reasoning tasks\"}, {\"s\": \"COGS\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"controlled text generation\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"evaluation metrics development\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"open domain question answering\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"data-to-text generation\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"commonsense causality\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"explainable recommendation\"}, {\"s\": \"commonsense question answering\", \"p\": \"Part-of\", \"o\": \"Natural Language Processing\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"attribute-based Controlled Text Generation\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"semantic parsing\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"abductive reasoning tasks\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"cross-prompt automated essay scoring\"}, {\"s\": \"text generation\", \"p\": \"Part-of\", \"o\": \"Open-ended Long Text Generation\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"pre-training models\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"multi-document question answering\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency in summarization\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"audio-visual text generation\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"multimodal sarcasm explanation\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"assessing factual correctness\"}, {\"s\": \"Task-Oriented Dialogue System\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"TempReason\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"multi-aspect controllable text generation\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"event relational reasoning tasks\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"few-shot summarization\"}, {\"s\": \"commonsense question answering\", \"p\": \"Compare\", \"o\": \"open-domain question answering\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"temporal reasoning capability\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"product question answering\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"document-level text simplification\"}, {\"s\": \"CLEVR-CoGenT\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"commonsense question answering\", \"p\": \"Compare\", \"o\": \"Table Question Answering\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"event detection\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"lexical relations prediction\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"natural language inference\", \"p\": \"Used-for\", \"o\": \"reducing reliance on shortcuts\"}, {\"s\": \"dialogue system\", \"p\": \"Part-of\", \"o\": \"chatbot\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"knowledge graphs\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}, {\"s\": \"open-domain dialogue system\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"competitive programming task\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"open-domain dialogue systems\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"knowledge graphs\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"non-factoid question answering\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"benchmarking models\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"retrieval model\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"long-form question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Automatic evaluation\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"multi-modal reasoning task\"}, {\"s\": \"TRAC\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"SCAN\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"out-of-distribution performance\"}, {\"s\": \"reasoning\", \"p\": \"Part-of\", \"o\": \"reasoning datasets\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"fine-tuning models\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"augmenting training data\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Multimodal summarization\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"in-distribution accuracy\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"language models\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"natural language inference\", \"p\": \"Part-of\", \"o\": \"natural language understanding\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"multi-document summarization\"}, {\"s\": \"Automatic evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"shot learning\", \"p\": \"Hyponym-Of\", \"o\": \"zero-shot learning\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"dialogue summarization\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"fairness-related harms in AI systems\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Document-level text simplification\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"visual spatial description\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"hierarchical text classification\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"discourse analysis\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"large language models\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"form question answering\", \"p\": \"Hyponym-Of\", \"o\": \"question answering\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"retrieval-based dialogue system\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"video-grounded dialogue generation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"reasoning about everyday matters\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"compositionality\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"emotion recognition in conversation\"}, {\"s\": \"natural language inference\", \"p\": \"Hyponym-Of\", \"o\": \"natural language processing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"commonsense causal relations\"}, {\"s\": \"DHLK\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [14:23<00:00, 43.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for concept question answering: [{\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"open-domain question answering\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"generating useful intermediate context\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"retrieval model evaluation\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"elaboration generation\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"commonsense reasoning\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"cross-document informational relations\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"semantic representation\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"Table Question Answering (TQA)\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"temporal reasoning\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"information retrieval\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"long-form answers evaluation\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"knowledge base question answering (KBQA)\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"open domain question answering (ODQA)\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"multi-hop question answering\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"Table Question Answering (TableQA)\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"cross-lingual transfer\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"Answer Sentence Selection (AS2)\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"Event Extraction\"}, {\"s\": \"question answering\", \"p\": \"Used-for\", \"o\": \"dense retrieval models evaluation\"}, {\"s\": \"form question answering\", \"p\": \"Hyponym-Of\", \"o\": \"question answering\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"question answering\"}, {\"s\": \"summarization dataset\", \"p\": \"Evaluate-for\", \"o\": \"summarization performance\"}, {\"s\": \"natural language explanation\", \"p\": \"Hyponym-Of\", \"o\": \"text explanation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"document-level relation extraction\", \"p\": \"Part-of\", \"o\": \"relation extraction\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Abstractive summarization\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"instruction following\"}, {\"s\": \"RSTformer\", \"p\": \"Hyponym-Of\", \"o\": \"summarization model\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"generating free-text rationales\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"model's reasoning\"}, {\"s\": \"CrossSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"relation extraction docre\", \"p\": \"Is-a-Prerequisite-of\", \"o\": \"event temporal relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"inconsistencies detection\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"extractive summarization\"}, {\"s\": \"summarization evaluation\", \"p\": \"Used-for\", \"o\": \"Assessing factual consistency\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"commonsense If-Then reasoning tasks\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"decision making\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"abstractive summarization\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"real-world knowledge evaluation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"event detection and event-relation extraction tasks\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"conditional inference on joint textual and visual clues\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"enhancing language representation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"free-text rationales\"}, {\"s\": \"argument extraction\", \"p\": \"Evaluate-for\", \"o\": \"model generalizability\"}, {\"s\": \"Human evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"commonsense question answering\"}, {\"s\": \"QAmden\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Dialogue summarization\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"chain-of-thought\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"multi-document non-factoid question answering\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"counterfactual reasoning tasks\"}, {\"s\": \"COGS\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"Multi-DYLE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"controlled text generation\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"evaluation metrics development\"}, {\"s\": \"DIONYSUS\", \"p\": \"Hyponym-Of\", \"o\": \"summarization system\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"open domain question answering\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"data-to-text generation\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"commonsense causality\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"guiding model reasoning\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"explainable recommendation\"}, {\"s\": \"commonsense question answering\", \"p\": \"Part-of\", \"o\": \"Natural Language Processing\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"attribute-based Controlled Text Generation\"}, {\"s\": \"argument extraction\", \"p\": \"Used-for\", \"o\": \"attribute extraction\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"semantic parsing\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"abductive reasoning tasks\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"cross-prompt automated essay scoring\"}, {\"s\": \"text generation\", \"p\": \"Part-of\", \"o\": \"Open-ended Long Text Generation\"}, {\"s\": \"pre-trained language models\", \"p\": \"Used-for\", \"o\": \"relation extraction\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"pre-training models\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"multi-document downstream tasks\"}, {\"s\": \"argument extraction\", \"p\": \"Part-of\", \"o\": \"Event Argument Extraction (EAE)\"}, {\"s\": \"text rationale\", \"p\": \"Used-for\", \"o\": \"explainable NLP\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"improving classification\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"new information\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"multi-document question answering\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency in summarization\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"audio-visual text generation\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"multimodal sarcasm explanation\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"multimodal relation extraction\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"assessing factual correctness\"}, {\"s\": \"Task-Oriented Dialogue System\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"TempReason\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"relation extraction docre\", \"p\": \"Evaluate-for\", \"o\": \"document-level relation extraction\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"multi-aspect controllable text generation\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"event relational reasoning tasks\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"few-shot summarization\"}, {\"s\": \"commonsense question answering\", \"p\": \"Compare\", \"o\": \"open-domain question answering\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"temporal reasoning capability\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"product question answering\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"product question answering\"}, {\"s\": \"relation extraction\", \"p\": \"Used-for\", \"o\": \"acquisition of relational facts\"}, {\"s\": \"CSJ\", \"p\": \"Evaluate-for\", \"o\": \"document-level text simplification\"}, {\"s\": \"CLEVR-CoGenT\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"commonsense question answering\", \"p\": \"Compare\", \"o\": \"Table Question Answering\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"event detection\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"lexical relations prediction\"}, {\"s\": \"natural language explanation\", \"p\": \"Compare\", \"o\": \"text-to-image disambiguation\"}, {\"s\": \"natural language inference\", \"p\": \"Used-for\", \"o\": \"reducing reliance on shortcuts\"}, {\"s\": \"dialogue system\", \"p\": \"Part-of\", \"o\": \"chatbot\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"human utility\"}, {\"s\": \"knowledge graphs\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}, {\"s\": \"open-domain dialogue system\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"competitive programming task\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"open-domain dialogue systems\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"knowledge graphs\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"non-factoid question answering\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"benchmarking models\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"retrieval model\"}, {\"s\": \"form question answering\", \"p\": \"Conjunction\", \"o\": \"long-form question answering\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Automatic evaluation\"}, {\"s\": \"CSJ\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"ExplainMeetSum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"multi-modal reasoning task\"}, {\"s\": \"TRAC\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"SCAN\", \"p\": \"Hyponym-Of\", \"o\": \"reasoning datasets\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"ambiguity resolution\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"out-of-distribution performance\"}, {\"s\": \"reasoning\", \"p\": \"Part-of\", \"o\": \"reasoning datasets\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"fine-tuning models\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"summarization dataset\", \"p\": \"Used-for\", \"o\": \"augmenting training data\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Multimodal summarization\"}, {\"s\": \"natural language inference\", \"p\": \"Evaluate-for\", \"o\": \"in-distribution accuracy\"}, {\"s\": \"relation extraction docre\", \"p\": \"Used-for\", \"o\": \"knowledge graph construction\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"language models\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"reasoning and prediction processes\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"relation extraction\", \"p\": \"Part-of\", \"o\": \"information extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"gender-fairness\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"natural language inference\", \"p\": \"Part-of\", \"o\": \"natural language understanding\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"multi-document summarization\"}, {\"s\": \"Automatic evaluation\", \"p\": \"Evaluate-for\", \"o\": \"summarization evaluation\"}, {\"s\": \"shot learning\", \"p\": \"Hyponym-Of\", \"o\": \"zero-shot learning\"}, {\"s\": \"MM-Sum\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"question answering qa\", \"p\": \"Used-for\", \"o\": \"open-domain question answering\"}, {\"s\": \"relation extraction docre\", \"p\": \"Compare\", \"o\": \"multilingual relation extraction\"}, {\"s\": \"natural language explanation\", \"p\": \"Part-of\", \"o\": \"natural language processing\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"dialogue summarization\"}, {\"s\": \"natural language explanation\", \"p\": \"Used-for\", \"o\": \"justifying predictions\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"fairness-related harms in AI systems\"}, {\"s\": \"summarization evaluation\", \"p\": \"Evaluate-for\", \"o\": \"Document-level text simplification\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"visual spatial description\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"hierarchical text classification\"}, {\"s\": \"summarization evaluation\", \"p\": \"Part-of\", \"o\": \"Human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"classification performance\"}, {\"s\": \"event relation\", \"p\": \"Used-for\", \"o\": \"discourse analysis\"}, {\"s\": \"commonsense question answering\", \"p\": \"Evaluate-for\", \"o\": \"large language models\"}, {\"s\": \"relation extraction docre\", \"p\": \"Part-of\", \"o\": \"Universal Information Extraction\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"human evaluation\"}, {\"s\": \"natural language explanation\", \"p\": \"Evaluate-for\", \"o\": \"model reasoning\"}, {\"s\": \"text rationale\", \"p\": \"Evaluate-for\", \"o\": \"rationale-label pairs\"}, {\"s\": \"retrieval-based dialogue system\", \"p\": \"Hyponym-Of\", \"o\": \"dialogue system\"}, {\"s\": \"RoSE\", \"p\": \"Part-of\", \"o\": \"summarization system\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"video-grounded dialogue generation\"}, {\"s\": \"question answering\", \"p\": \"Part-of\", \"o\": \"commonsense question answering\"}, {\"s\": \"commonsense question answering\", \"p\": \"Used-for\", \"o\": \"reasoning about everyday matters\"}, {\"s\": \"summarization dataset\", \"p\": \"Part-of\", \"o\": \"cross-lingual summarization\"}, {\"s\": \"summarization system\", \"p\": \"Used-for\", \"o\": \"dialogue summarization\"}, {\"s\": \"form question answering\", \"p\": \"Evaluate-for\", \"o\": \"compositionality\"}, {\"s\": \"reasoning datasets\", \"p\": \"Part-of\", \"o\": \"instruction following\"}, {\"s\": \"text generation\", \"p\": \"Evaluate-for\", \"o\": \"factual consistency evaluation\"}, {\"s\": \"text generation\", \"p\": \"Used-for\", \"o\": \"emotion recognition in conversation\"}, {\"s\": \"natural language inference\", \"p\": \"Hyponym-Of\", \"o\": \"natural language processing\"}, {\"s\": \"question answering qa\", \"p\": \"Part-of\", \"o\": \"semantic parsing\"}, {\"s\": \"reasoning task\", \"p\": \"Used-for\", \"o\": \"commonsense causal relations\"}, {\"s\": \"DHLK\", \"p\": \"Used-for\", \"o\": \"commonsense question answering\"}]\n",
      "/n /n /n\n",
      "Total fused triples: 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fused_triples = fuse_triples(model, candidate_triples, relation_def, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(fused_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving triples list to a text file\n",
    "\n",
    "with open(fused_triples_path, \"w\") as f:\n",
    "    for t in fused_triples:\n",
    "        f.write(json.dumps({\"s\": t[0], \"p\": t[1], \"o\": t[2]}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "class Neo4jTripleStore:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def insert_triple(self, subject, relation, obj):\n",
    "        with self.driver.session() as session:\n",
    "            session.execute_write(self._create_triple, subject, relation, obj)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_triple(tx, subject, relation, obj):\n",
    "        query = \"\"\"\n",
    "        MERGE (s:Concept {name: $subject})\n",
    "        MERGE (o:Concept {name: $object})\n",
    "        MERGE (s)-[r:RELATION {type: $relation}]->(o)\n",
    "        \"\"\"\n",
    "        tx.run(query, subject=subject, relation=relation, object=obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored all fused triples into Neo4j.\n"
     ]
    }
   ],
   "source": [
    "neo4j_store = Neo4jTripleStore(uri=\"neo4j+s://68cfeea5.databases.neo4j.io\", user=\"neo4j\", password=\"Z2D8tI5LWCCkcxR7Fbp0nb5X4V0sxwhiHwxOtXHe-Dc\")\n",
    "for s, p, o in fused_triples:\n",
    "    neo4j_store.insert_triple(s, p, o)\n",
    "neo4j_store.close()\n",
    "print(\"Stored all fused triples into Neo4j.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fused triples path\n",
    "fused_triples_path = \"outputs/sample/modified_prompt/fused_triples_sample.json\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KGRag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
