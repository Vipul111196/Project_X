{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c4b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Setup & Imports\n",
    "import os\n",
    "import asyncio\n",
    "from rdflib import Graph as RDFGraph\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "from neo4j_graphrag.indexes import create_vector_index\n",
    "from neo4j_graphrag.embeddings import OpenAIEmbeddings\n",
    "from neo4j_graphrag.llm.openai_llm import OpenAILLM\n",
    "from neo4j_graphrag.experimental.components.text_splitters.fixed_size_splitter import FixedSizeSplitter\n",
    "from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline\n",
    "from neo4j_graphrag.experimental.components.resolver import SinglePropertyExactMatchResolver\n",
    "from neo4j_graphrag.retrievers import VectorRetriever, Text2CypherRetriever\n",
    "from neo4j_graphrag.generation import GraphRAG\n",
    "\n",
    "from src.utils import getSchemaFromOnto, getNLOntology, getPKs\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ffdc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "## 2. Load Environment Variables\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "uri = os.getenv(\"NEO4J_URI\")\n",
    "user = os.getenv(\"NEO4J_USERNAME\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "AUTH = (user, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2856c04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "bolt://localhost:7687\n",
      "neo4j\n",
      "password\n"
     ]
    }
   ],
   "source": [
    "print(api_key)\n",
    "print(uri)\n",
    "print(user)\n",
    "print(password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a79ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(uri, auth=AUTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f71183",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Create Vector Index\n",
    "INDEX_NAME = \"chunk-index\"\n",
    "DIMENSION = 3072\n",
    "create_vector_index(\n",
    "    driver,\n",
    "    INDEX_NAME,\n",
    "    label=\"Chunk\",\n",
    "    embedding_property=\"embedding\",\n",
    "    dimensions=DIMENSION,\n",
    "    similarity_fn=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b593e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader  \n",
    "\n",
    "# Creating a function to read Multiple PDF files  \n",
    "def process_pdfs_in_directory(directory_path):  \n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for filename in os.listdir(directory_path):  \n",
    "        if filename.endswith(\".pdf\"):  \n",
    "            file_path = os.path.join(directory_path, filename) \n",
    "            pdf_loader = PyMuPDFLoader(file_path=file_path)\n",
    "            document = pdf_loader.load()\n",
    "            print(f\"File loading done for: {filename}\")\n",
    "            documents.append(document)\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95dc39b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loading done for: 2022 Q3 AAPL.pdf\n"
     ]
    }
   ],
   "source": [
    "all_docs = process_pdfs_in_directory(\"data/\")  # Specify the directory containing your PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d185e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of basedocs is now 28\n"
     ]
    }
   ],
   "source": [
    "# Initialize the base list  \n",
    "base_docs = []  \n",
    "  \n",
    "# Flatten the all_docs structure and extend base_docs  \n",
    "for doc_list in all_docs:\n",
    "    base_docs.extend(doc_list)  \n",
    "  \n",
    "print('Length of basedocs is now ' + str(len(base_docs))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e2fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of documents saved to data/Pickle_File/base_docs.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle  \n",
    "file_path = 'data/Pickle_File/base_docs.pkl'  \n",
    "  \n",
    "# Serialize the list of Document objects and save it to a file  \n",
    "with open(file_path, 'wb') as file:  \n",
    "    pickle.dump(base_docs, file)  \n",
    "  \n",
    "print(f\"List of documents saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaef308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of documents loaded successfully: 28\n"
     ]
    }
   ],
   "source": [
    "import pickle   \n",
    "  \n",
    "# Specify the file path where your list of documents is saved  \n",
    "file_path = 'data/Pickle_File/base_docs.pkl' \n",
    "  \n",
    "# Deserialize the file content back into a list of Document objects  \n",
    "with open(file_path, 'rb') as file:  \n",
    "    base_docs = pickle.load(file)\n",
    "  \n",
    "print(\"List of documents loaded successfully: \" + str(len(base_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f1d1780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)\n",
    "\n",
    "chunks = text_splitter.split_documents(base_docs)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44dc6712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2022-07-29T06:03:21-04:00', 'source': 'data/2022 Q3 AAPL.pdf', 'file_path': 'data/2022 Q3 AAPL.pdf', 'total_pages': 28, 'format': 'PDF 1.4', 'title': '0000320193-22-000070', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-Q filed on 2022-07-29 for the period ending 2022-06-25', 'keywords': '0000320193-22-000070; ; 10-Q', 'moddate': '2022-07-29T06:03:28-04:00', 'trapped': '', 'encryption': 'Standard V2 R3 128-bit RC4', 'modDate': \"D:20220729060328-04'00'\", 'creationDate': \"D:20220729060321-04'00'\", 'page': 0}, page_content='UNITED STATES\\nSECURITIES AND EXCHANGE COMMISSION\\nWashington, D.C. 20549\\nFORM 10-Q\\n(Mark One)\\n‚òí QUARTERLY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\nFor the quarterly period ended June\\xa025, 2022\\nor\\n‚òê TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\nFor the transition period from \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 to \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0.\\nCommission File Number: 001-36743\\nApple Inc.\\n(Exact name of Registrant as specified in its charter)\\nCalifornia\\n94-2404110\\n(State or other jurisdiction\\nof incorporation or organization)\\n(I.R.S. Employer Identification No.)\\nOne Apple Park Way\\nCupertino, California\\n95014\\n(Address of principal executive offices)\\n(Zip Code)\\n(408) 996-1010\\n(Registrant‚Äôs telephone number, including area code)\\nSecurities registered pursuant to Section 12(b) of the Act:\\nTitle of each class\\nTrading symbol(s)\\nName of each exchange on which registered\\nCommon Stock, $0.00001 par value per share\\nAAPL\\nThe Nasdaq Stock Market LLC\\n1.000% Notes due 2022\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n1.375% Notes due 2024\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n0.000% Notes due 2025\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n0.875% Notes due 2025\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n1.625% Notes due 2026\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n2.000% Notes due 2027\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n1.375% Notes due 2029\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n3.050% Notes due 2029\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n0.500% Notes due 2031\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n3.600% Notes due 2042\\n‚Äî')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f6ef97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in chunks:  \n",
    "    del doc.metadata['source']  \n",
    "    file_path = doc.metadata['file_path']  \n",
    "    doc.metadata['file_name'] = os.path.basename(file_path)  \n",
    "    del doc.metadata['file_path']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4056032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2022-07-29T06:03:21-04:00', 'total_pages': 28, 'format': 'PDF 1.4', 'title': '0000320193-22-000070', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-Q filed on 2022-07-29 for the period ending 2022-06-25', 'keywords': '0000320193-22-000070; ; 10-Q', 'moddate': '2022-07-29T06:03:28-04:00', 'trapped': '', 'encryption': 'Standard V2 R3 128-bit RC4', 'modDate': \"D:20220729060328-04'00'\", 'creationDate': \"D:20220729060321-04'00'\", 'page': 0, 'file_name': '2022 Q3 AAPL.pdf'}, page_content='UNITED STATES\\nSECURITIES AND EXCHANGE COMMISSION\\nWashington, D.C. 20549\\nFORM 10-Q\\n(Mark One)\\n‚òí QUARTERLY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\nFor the quarterly period ended June\\xa025, 2022\\nor\\n‚òê TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\nFor the transition period from \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 to \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0.\\nCommission File Number: 001-36743\\nApple Inc.\\n(Exact name of Registrant as specified in its charter)\\nCalifornia\\n94-2404110\\n(State or other jurisdiction\\nof incorporation or organization)\\n(I.R.S. Employer Identification No.)\\nOne Apple Park Way\\nCupertino, California\\n95014\\n(Address of principal executive offices)\\n(Zip Code)\\n(408) 996-1010\\n(Registrant‚Äôs telephone number, including area code)\\nSecurities registered pursuant to Section 12(b) of the Act:\\nTitle of each class\\nTrading symbol(s)\\nName of each exchange on which registered\\nCommon Stock, $0.00001 par value per share\\nAAPL\\nThe Nasdaq Stock Market LLC\\n1.000% Notes due 2022\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n1.375% Notes due 2024\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n0.000% Notes due 2025\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n0.875% Notes due 2025\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n1.625% Notes due 2026\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n2.000% Notes due 2027\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n1.375% Notes due 2029\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n3.050% Notes due 2029\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n0.500% Notes due 2031\\n‚Äî\\nThe Nasdaq Stock Market LLC\\n3.600% Notes due 2042\\n‚Äî')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbb2d1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ex: <http://example.org/financial/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "ex:disclosesRisk a <http://www.w3.org/2002/07/owl#ObjectProperty> ;\n",
      "    rdfs:label \"Discloses Risk\" ;\n",
      "    rdfs:comment \"A report that describes risk factors.\" ;\n",
      "    rdfs:domain ex:FinancialReport ;\n",
      "    rdfs:range ex:RiskFactor .\n",
      "\n",
      "ex:dividendDeclared a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Dividend Declared\" ;\n",
      "    rdfs:comment \"Reported dividend for the time period.\" ;\n",
      "    rdfs:domain ex:FinancialReport .\n",
      "\n",
      "ex:hasStockInfo a <http://www.w3.org/2002/07/owl#ObjectProperty> ;\n",
      "    rdfs:label \"Has Stock Info\" ;\n",
      "    rdfs:comment \"The company has associated stock information.\" ;\n",
      "    rdfs:domain ex:Company ;\n",
      "    rdfs:range ex:StockInformation .\n",
      "\n",
      "ex:includes a <http://www.w3.org/2002/07/owl#ObjectProperty> ;\n",
      "    rdfs:label \"Includes\" ;\n",
      "    rdfs:comment \"A report includes an income statement.\" ;\n",
      "    rdfs:domain ex:FinancialReport ;\n",
      "    rdfs:range ex:IncomeStatement .\n",
      "\n",
      "ex:includesBalance a <http://www.w3.org/2002/07/owl#ObjectProperty> ;\n",
      "    rdfs:label \"Includes Balance Sheet\" ;\n",
      "    rdfs:comment \"A report includes a balance sheet.\" ;\n",
      "    rdfs:domain ex:FinancialReport ;\n",
      "    rdfs:range ex:BalanceSheet .\n",
      "\n",
      "ex:name a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Name\" ;\n",
      "    rdfs:comment \"Official name of the company.\" ;\n",
      "    rdfs:domain ex:Company .\n",
      "\n",
      "ex:relatedTo a <http://www.w3.org/2002/07/owl#ObjectProperty> ;\n",
      "    rdfs:label \"Related To\" ;\n",
      "    rdfs:comment \"The company that filed the report.\" ;\n",
      "    rdfs:domain ex:FinancialReport ;\n",
      "    rdfs:range ex:Company .\n",
      "\n",
      "ex:reportNumber a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Report Number\" ;\n",
      "    rdfs:comment \"The EDGAR report number or filing code.\" ;\n",
      "    rdfs:domain ex:FinancialReport .\n",
      "\n",
      "ex:sharesOutstanding a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Shares Outstanding\" ;\n",
      "    rdfs:comment \"Number of shares available.\" ;\n",
      "    rdfs:domain ex:StockInformation .\n",
      "\n",
      "ex:temporalCoverage a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Temporal Coverage\" ;\n",
      "    rdfs:comment \"Time period covered by the report.\" ;\n",
      "    rdfs:domain ex:FinancialReport .\n",
      "\n",
      "ex:tickerSymbol a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Ticker Symbol\" ;\n",
      "    rdfs:comment \"Stock ticker symbol, e.g. AAPL.\" ;\n",
      "    rdfs:domain ex:Company .\n",
      "\n",
      "ex:unitCode a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Unit Code\" ;\n",
      "    rdfs:comment \"Currency or measurement unit used.\" ;\n",
      "    rdfs:domain ex:FinancialReport .\n",
      "\n",
      "ex:BalanceSheet a <http://www.w3.org/2002/07/owl#Class> ;\n",
      "    rdfs:label \"Balance Sheet\" ;\n",
      "    rdfs:comment \"Summarizes assets, liabilities, and equity.\" .\n",
      "\n",
      "ex:IncomeStatement a <http://www.w3.org/2002/07/owl#Class> ;\n",
      "    rdfs:label \"Income Statement\" ;\n",
      "    rdfs:comment \"Shows revenue, expenses, and profit.\" .\n",
      "\n",
      "ex:RiskFactor a <http://www.w3.org/2002/07/owl#Class> ;\n",
      "    rdfs:label \"Risk Factor\" ;\n",
      "    rdfs:comment \"Potential risk disclosed by the company.\" .\n",
      "\n",
      "ex:StockInformation a <http://www.w3.org/2002/07/owl#Class> ;\n",
      "    rdfs:label \"Stock Information\" ;\n",
      "    rdfs:comment \"Public stock data reported by the company.\" .\n",
      "\n",
      "ex:Company a <http://www.w3.org/2002/07/owl#Class> ;\n",
      "    rdfs:label \"Company\" ;\n",
      "    rdfs:comment \"A legal entity that files financial reports.\" .\n",
      "\n",
      "ex:FinancialReport a <http://www.w3.org/2002/07/owl#Class> ;\n",
      "    rdfs:label \"Financial Report\" ;\n",
      "    rdfs:comment \"A periodic report (10-K, 10-Q) describing a company's financials.\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"onto/improved_financial_ontology.ttl\", \"r\") as f:\n",
    "    onto = f.read()\n",
    "    print(onto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16832ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SchemaConfig(entities={'FinancialReport': {'label': 'FinancialReport', 'description': 'A 10-Q or 10-K financial disclosure submitted by a public company.', 'properties': [{'name': 'reportNumber', 'type': 'STRING', 'description': 'The SEC form number such as 10-Q or 10-K.'}]}, 'Company': {'label': 'Company', 'description': 'A publicly traded corporation that submits financial reports.', 'properties': []}, 'FinancialStatement': {'label': 'FinancialStatement', 'description': 'A general class for financial statements.', 'properties': []}, 'IncomeStatement': {'label': 'IncomeStatement', 'description': 'An income statement detailing revenue, expenses, and net income.', 'properties': []}, 'BalanceSheet': {'label': 'BalanceSheet', 'description': 'A balance sheet showing assets, liabilities, and equity.', 'properties': []}, 'CashFlowStatement': {'label': 'CashFlowStatement', 'description': 'A statement of cash inflows and outflows.', 'properties': []}, 'ShareholdersEquityStatement': {'label': 'ShareholdersEquityStatement', 'description': 'Tracks changes in equity of shareholders over a period.', 'properties': []}, 'FinancialMetric': {'label': 'FinancialMetric', 'description': 'A quantitative value in a financial report, like Net Income or Revenue.', 'properties': [{'name': 'temporalCoverage', 'type': 'STRING', 'description': 'Time span for which a metric applies (e.g., Q3 2022).'}, {'name': 'unitCode', 'type': 'STRING', 'description': 'Currency or unit, e.g., USD.'}, {'name': 'value', 'type': 'STRING', 'description': 'The actual numeric value of the metric.'}]}, 'StockInformation': {'label': 'StockInformation', 'description': 'Details about company shares, dividends, etc.', 'properties': [{'name': 'tickerSymbol', 'type': 'STRING', 'description': 'The stock ticker symbol, e.g., AAPL, MSFT.'}, {'name': 'sharesOutstanding', 'type': 'STRING', 'description': 'Number of shares currently outstanding.'}, {'name': 'dividendDeclared', 'type': 'STRING', 'description': 'Dividend declared per share for the quarter.'}]}, 'RiskFactor': {'label': 'RiskFactor', 'description': 'Qualitative risks disclosed by a company.', 'properties': []}, 'LegalProceeding': {'label': 'LegalProceeding', 'description': 'A legal action or case referenced in the financial report.', 'properties': []}, 'MarketDisclosure': {'label': 'MarketDisclosure', 'description': 'Narrative discussion on business, market conditions, and trends.', 'properties': []}}, relations={'hasFinancialStatement': {'label': 'hasFinancialStatement', 'description': 'Links a report to the financial statements it contains.', 'properties': []}, 'hasMetric': {'label': 'hasMetric', 'description': 'Connects a statement to its metrics like revenue or net income.', 'properties': []}, 'hasRiskFactor': {'label': 'hasRiskFactor', 'description': 'Connects a report to its described risk factors.', 'properties': []}, 'hasLegalProceeding': {'label': 'hasLegalProceeding', 'description': 'Legal proceedings discussed in the report.', 'properties': []}, 'hasStockInfo': {'label': 'hasStockInfo', 'description': 'Connects the report to stock/share-related data.', 'properties': []}, 'relatedTo': {'label': 'relatedTo', 'description': 'General relationship to a company or segment.', 'properties': []}}, potential_schema=[('FinancialReport', 'hasFinancialStatement', 'FinancialStatement'), ('FinancialStatement', 'hasMetric', 'FinancialMetric'), ('FinancialReport', 'hasRiskFactor', 'RiskFactor'), ('FinancialReport', 'hasLegalProceeding', 'LegalProceeding'), ('FinancialReport', 'hasStockInfo', 'StockInformation'), ('MarketDisclosure', 'relatedTo', 'Company')])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 3. Load Ontology and Schema\n",
    "from IPython.display import display\n",
    "\n",
    "g = RDFGraph()\n",
    "g.parse(\"onto/financial_report_ontology.ttl\")\n",
    "neo4j_schema = getSchemaFromOnto(g) # Load the schema from the ontology\n",
    "display(neo4j_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "52ef8cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FinancialReport', 'hasFinancialStatement', 'FinancialStatement'),\n",
       " ('FinancialStatement', 'hasMetric', 'FinancialMetric'),\n",
       " ('FinancialReport', 'hasRiskFactor', 'RiskFactor'),\n",
       " ('FinancialReport', 'hasLegalProceeding', 'LegalProceeding'),\n",
       " ('FinancialReport', 'hasStockInfo', 'StockInformation'),\n",
       " ('MarketDisclosure', 'relatedTo', 'Company')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo4j_schema.potential_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7b271b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([{'label': 'FinancialReport', 'description': 'A 10-Q or 10-K financial disclosure submitted by a public company.', 'properties': [{'name': 'reportNumber', 'type': 'STRING', 'description': 'The SEC form number such as 10-Q or 10-K.'}]}, {'label': 'Company', 'description': 'A publicly traded corporation that submits financial reports.', 'properties': []}, {'label': 'FinancialStatement', 'description': 'A general class for financial statements.', 'properties': []}, {'label': 'IncomeStatement', 'description': 'An income statement detailing revenue, expenses, and net income.', 'properties': []}, {'label': 'BalanceSheet', 'description': 'A balance sheet showing assets, liabilities, and equity.', 'properties': []}, {'label': 'CashFlowStatement', 'description': 'A statement of cash inflows and outflows.', 'properties': []}, {'label': 'ShareholdersEquityStatement', 'description': 'Tracks changes in equity of shareholders over a period.', 'properties': []}, {'label': 'FinancialMetric', 'description': 'A quantitative value in a financial report, like Net Income or Revenue.', 'properties': [{'name': 'temporalCoverage', 'type': 'STRING', 'description': 'Time span for which a metric applies (e.g., Q3 2022).'}, {'name': 'unitCode', 'type': 'STRING', 'description': 'Currency or unit, e.g., USD.'}, {'name': 'value', 'type': 'STRING', 'description': 'The actual numeric value of the metric.'}]}, {'label': 'StockInformation', 'description': 'Details about company shares, dividends, etc.', 'properties': [{'name': 'tickerSymbol', 'type': 'STRING', 'description': 'The stock ticker symbol, e.g., AAPL, MSFT.'}, {'name': 'sharesOutstanding', 'type': 'STRING', 'description': 'Number of shares currently outstanding.'}, {'name': 'dividendDeclared', 'type': 'STRING', 'description': 'Dividend declared per share for the quarter.'}]}, {'label': 'RiskFactor', 'description': 'Qualitative risks disclosed by a company.', 'properties': []}, {'label': 'LegalProceeding', 'description': 'A legal action or case referenced in the financial report.', 'properties': []}, {'label': 'MarketDisclosure', 'description': 'Narrative discussion on business, market conditions, and trends.', 'properties': []}])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities=neo4j_schema.entities.values()\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99d093c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([{'label': 'hasFinancialStatement', 'description': 'Links a report to the financial statements it contains.', 'properties': []}, {'label': 'hasMetric', 'description': 'Connects a statement to its metrics like revenue or net income.', 'properties': []}, {'label': 'hasRiskFactor', 'description': 'Connects a report to its described risk factors.', 'properties': []}, {'label': 'hasLegalProceeding', 'description': 'Legal proceedings discussed in the report.', 'properties': []}, {'label': 'hasStockInfo', 'description': 'Connects the report to stock/share-related data.', 'properties': []}, {'label': 'relatedTo', 'description': 'General relationship to a company or segment.', 'properties': []}])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations=neo4j_schema.relations.values()\n",
    "relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605ca33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node Labels:\n",
      "FinancialReport: A 10-Q or 10-K financial disclosure submitted by a public company.\n",
      "Company: A publicly traded corporation that submits financial reports.\n",
      "FinancialStatement: A general class for financial statements.\n",
      "IncomeStatement: An income statement detailing revenue, expenses, and net income.\n",
      "BalanceSheet: A balance sheet showing assets, liabilities, and equity.\n",
      "CashFlowStatement: A statement of cash inflows and outflows.\n",
      "ShareholdersEquityStatement: Tracks changes in equity of shareholders over a period.\n",
      "FinancialMetric: A quantitative value in a financial report, like Net Income or Revenue.\n",
      "StockInformation: Details about company shares, dividends, etc.\n",
      "RiskFactor: Qualitative risks disclosed by a company.\n",
      "LegalProceeding: A legal action or case referenced in the financial report.\n",
      "MarketDisclosure: Narrative discussion on business, market conditions, and trends.\n",
      "\n",
      "Node Properties:\n",
      "reportNumber: Attribute that applies to entities of type FinancialReport. It represents The SEC form number such as 10-Q or 10-K.\n",
      "temporalCoverage: Attribute that applies to entities of type FinancialMetric. It represents Time span for which a metric applies (e.g., Q3 2022).\n",
      "unitCode: Attribute that applies to entities of type FinancialMetric. It represents Currency or unit, e.g., USD.\n",
      "value: Attribute that applies to entities of type FinancialMetric. It represents The actual numeric value of the metric.\n",
      "tickerSymbol: Attribute that applies to entities of type StockInformation. It represents The stock ticker symbol, e.g., AAPL, MSFT.\n",
      "sharesOutstanding: Attribute that applies to entities of type StockInformation. It represents Number of shares currently outstanding.\n",
      "dividendDeclared: Attribute that applies to entities of type StockInformation. It represents Dividend declared per share for the quarter.\n",
      "\n",
      "Relationships:\n",
      "hasFinancialStatement: Relationship that connects entities of type FinancialReport to entities of type FinancialStatement. It represents Links a report to the financial statements it contains.\n",
      "hasMetric: Relationship that connects entities of type FinancialStatement to entities of type FinancialMetric. It represents Connects a statement to its metrics like revenue or net income.\n",
      "hasRiskFactor: Relationship that connects entities of type FinancialReport to entities of type RiskFactor. It represents Connects a report to its described risk factors.\n",
      "hasLegalProceeding: Relationship that connects entities of type FinancialReport to entities of type LegalProceeding. It represents Legal proceedings discussed in the report.\n",
      "hasStockInfo: Relationship that connects entities of type FinancialReport to entities of type StockInformation. It represents Connects the report to stock/share-related data.\n",
      "relatedTo: Relationship that connects entities of type MarketDisclosure to entities of type Company. It represents General relationship to a company or segment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nl_ontology = getNLOntology(g)\n",
    "print(nl_ontology) # Load the NL ontology from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e6a9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import KnowledgeGraphLLM\n",
    "# from langchain_ollama import ChatOllama\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "llm_gpt_4o_mini = KnowledgeGraphLLM(model_name=\"gpt-4o-mini\", max_tokens=10000, api_key=api_key)\n",
    "\n",
    "llm_embedding_large_3 = OpenAIEmbeddings(api_key=api_key, model=\"text-embedding-3-large\")\n",
    "\n",
    "# llm_llama31_8b = ChatOllama(\n",
    "#     model=\"llama3.1:8b\",\n",
    "#     temperature=0,\n",
    "#     base_url = \"http://10.5.61.140:5000/\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "706f0149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"s\": \"France\", \"p\": \"hasCapital\", \"o\": \"Paris\", \"stype\": \"Country\", \"otype\": \"City\", \"value\": 0.0, \"unitCode\": \"\", \"temporalCoverage\": \"\", \"tickerSymbol\": \"\", \"dividendDeclared\": 0.0, \"sharesOutstanding\": 0.0, \"reportNumber\": \"\"}]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_gpt_4o_mini.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j_graphrag.embeddings import OpenAIEmbeddings\n",
    "# from neo4j_graphrag.llm.openai_llm import OpenAILLM\n",
    "\n",
    "# embedder = OpenAIEmbeddings(api_key=api_key, model=\"text-embedding-3-large\")\n",
    "# llm = OpenAILLM(api_key=api_key, model_name=\"gpt-4o-mini\", model_params={\"temperature\": 0, \"max_tokens\": 3000, \"response_format\": {\"type\": \"json_object\"}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692fa0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# # Multi Query: Different Perspectives\n",
    "# template_for_extracting_triples = \"\"\"\n",
    "# ### Follow the INSTRUCTION carefully:\n",
    "# You are an expert in **Domain** constructing a **knowledge graph**. Given a **Context** and **Ontologies defined in Natural Language**, **Entities Types**, **Relations Types** which is provided at the end, perform the following tasks:\n",
    "\n",
    "# #### **Step 1: Extract Relevant Entities**\n",
    "# - Extract entites based on the **Ontologies defined in Natural Language** provided below for the Given **Domain** and **Context**.\n",
    "\n",
    "# #### **Step 2: Use only and only the 7 predefined relation types, otherwise, you will be given penalty:**\n",
    "# - Extract relations based on the **Ontologies defined in Natural Language** provided below for the Given **Domain** and **Context**.\n",
    "\n",
    "# #### **Step 3: Identify Relationships and Generate Triplets**\n",
    "# - Determine the **relationships** between the *Entity Types** and the using the **triplet format**: (head_concept, relation, tail_concept)\n",
    "    \n",
    "# - Relationship Directionality: \n",
    "#     - Some relations are strictly directional, meaning (A, Evaluate-for, B) is valid, but (B, Evaluate-for, A) is not.\n",
    "#     - The relations \"Compare\" and \"Conjunction\" are bidirectional.\n",
    "#     - The query concept may be the head or tail in a triplet, but additional triplets between extracted concepts are encouraged.\n",
    "\n",
    "# #### **Step 4: Format the Output only and only use the given format, otherwise, you will be given penalty**\n",
    "# - Return ONLY and ONLY a list of triplets in this format: (concept, relation, concept)\n",
    "# - For Example:\n",
    "#     (natural language explanation, Used-for, model reasoning)\n",
    "#     (natural language explanation, Evaluate-for, classification performance)\n",
    "\n",
    "# #### Boundary Conditions:\n",
    "# - A tuple of triplet is considered eligible if it has only and only 3 items that is 2 concepts and one relationship between them\n",
    "\n",
    "# #### Important notes:\n",
    "# - No additional explanations, numbering, or extra text.\n",
    "\n",
    "# #### Here is the Domain: \n",
    "# {domain}\n",
    "\n",
    "# #### Here is the Ontologies defined in Natural Language:\n",
    "# {nl_ontology}\n",
    "\n",
    "# #### Here is the Context:\n",
    "# {chunk_text}\n",
    "# \"\"\"\n",
    "# prompt_template_for_extracting_triples = ChatPromptTemplate.from_template(template_for_extracting_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = prompt_template_for_extracting_triples.invoke({\"domain\":'Financial Report', \"chunk_text\":base_docs[5].page_content, \"nl_ontology\":nl_ontology})\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad5e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_chain = prompt_template_for_extracting_triples | llm_gpt_4o_mini \n",
    "# response = llm_chain.invoke({\"domain\":'Financial Report', \"chunk_text\":base_docs[5].page_content, \"nl_ontology\":nl_ontology})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227919e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dae0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_json_parse(s):\n",
    "    import ast\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception as e:\n",
    "        print(\"Parsing error:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432b8ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = safe_json_parse(response) # This will return a list of tuples if the parsing is successful, or None if it fails.\n",
    "# print(type(response[0]))\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Optional\n",
    "# from neo4j import GraphDatabase\n",
    "# from langchain.schema import Document\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# import os\n",
    "\n",
    "# class CustomKGPipeline:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         driver: GraphDatabase,\n",
    "#         embedder,\n",
    "#         llm,\n",
    "#         domain: str,\n",
    "#         ontology: str,\n",
    "#         prompt_path: str,\n",
    "#         neo4j_database: Optional[str] = None,\n",
    "#     ):\n",
    "#         self.driver = driver\n",
    "#         self.embedder = embedder\n",
    "#         self.llm = llm\n",
    "#         self.domain = domain\n",
    "#         self.ontology = ontology\n",
    "#         self.prompt_path = prompt_path\n",
    "#         self.neo4j_database = neo4j_database\n",
    "\n",
    "#         # We will load these later\n",
    "#         self.prompt = None\n",
    "\n",
    "#     def _load_prompt(self):\n",
    "#         if not os.path.exists(self.prompt_path):\n",
    "#             raise FileNotFoundError(f\"Prompt file not found at {self.prompt_path}\")\n",
    "#         with open(self.prompt_path, \"r\") as f:\n",
    "#             self.template_for_extracting_triples = f.read()\n",
    "\n",
    "\n",
    "#     def _render_prompt(self):\n",
    "#         if self.prompt is None:\n",
    "#             template = self._load_prompt()\n",
    "#             self.prompt_template = ChatPromptTemplate.from_template(self.template_for_extracting_triples)\n",
    "#         return self.prompt_template\n",
    "    \n",
    "#     def _create_chunk_nodes(self, docs: List[Document]):\n",
    "#         with self.driver.session(database=self.neo4j_database) as session:\n",
    "#             for i, doc in enumerate(docs):\n",
    "#                 text = doc.page_content\n",
    "#                 embedding = self.embedder.embed_query(text)\n",
    "\n",
    "#                 props = {\n",
    "#                     \"chunk_index\": i,\n",
    "#                     \"text\": text,\n",
    "#                     \"embedding\": embedding,\n",
    "#                 }\n",
    "\n",
    "#                 # Merge metadata into props\n",
    "#                 props.update(doc.metadata)\n",
    "\n",
    "#                 # Create the chunk node\n",
    "#                 session.run(\n",
    "#                     \"\"\"\n",
    "#                     MERGE (c:Chunk {chunk_index: $chunk_index})\n",
    "#                     SET c += $props\n",
    "#                     \"\"\",\n",
    "#                     chunk_index=i,\n",
    "#                     props=props,\n",
    "#                 )\n",
    "\n",
    "#                 # Create NEXT and PREVIOUS links if applicable\n",
    "#                 if i > 0:\n",
    "#                     session.run(\n",
    "#                         \"\"\"\n",
    "#                         MATCH (c1:Chunk {chunk_index: $prev}), (c2:Chunk {chunk_index: $curr})\n",
    "#                         MERGE (c1)-[:NEXT_CHUNK]->(c2)\n",
    "#                         MERGE (c2)-[:PREVIOUS_CHUNK]->(c1)\n",
    "#                         \"\"\",\n",
    "#                         prev=i - 1,\n",
    "#                         curr=i,\n",
    "#                     )\n",
    "\n",
    "\n",
    "#     def _extract_triples(self, prompt, chunk_text) -> List[tuple[str, str, str]]:\n",
    "#         \"\"\"\n",
    "#         Sends the prompt to LLM and parses the output into (s, p, o) triples.\n",
    "#         The LLM is expected to return JSON in the format:\n",
    "#         [{\"s\": \"Subject\", \"p\": \"Predicate\", \"o\": \"Object\"}, ...]\n",
    "#         \"\"\"\n",
    "#         triple_extracter_chain = prompt | self.llm | StrOutputParser()\n",
    "#         response = triple_extracter_chain.invoke({\n",
    "#             \"chunk_text\": chunk_text,\n",
    "#             \"domain\": self.domain,\n",
    "#             \"nl_ontology\": self.ontology\n",
    "#         })\n",
    "\n",
    "#         try:\n",
    "#             import ast\n",
    "#             data = ast.literal_eval(response)\n",
    "#         except Exception as e:\n",
    "#             print(\"Failed to parse LLM output:\", e)\n",
    "#             return []\n",
    "\n",
    "#         triples = []\n",
    "#         for item in data:\n",
    "#             s, p, o = item.get(\"s\"), item.get(\"p\"), item.get(\"o\")\n",
    "#             if s and p and o:\n",
    "#                 triples.append((s.strip(), p.strip(), o.strip()))\n",
    "\n",
    "#         return triples\n",
    "\n",
    "\n",
    "#     def _create_kg_from_chunks(self, docs: List[Document]):\n",
    "#         for i, doc in enumerate(docs):\n",
    "#             prompt = self._render_prompt()\n",
    "#             triples = self._extract_triples(prompt, doc.page_content)\n",
    "\n",
    "#             with self.driver.session(database=self.neo4j_database) as session:\n",
    "#                 for s, p, o in triples:\n",
    "#                     if not (s and p and o):\n",
    "#                         continue  # skip malformed ones\n",
    "\n",
    "#                     # Create entity nodes and connect\n",
    "#                     session.run(\n",
    "#                         f\"\"\"\n",
    "#                         MERGE (subj:Entity {{name: $s}})\n",
    "#                         MERGE (obj:Entity {{name: $o}})\n",
    "#                         MERGE (subj)-[:{p.upper()}]->(obj)\n",
    "#                         WITH subj, obj\n",
    "#                         MATCH (c:Chunk {{chunk_index: $chunk_index}})\n",
    "#                         MERGE (subj)-[:MENTIONED_IN]->(c)\n",
    "#                         MERGE (obj)-[:MENTIONED_IN]->(c)\n",
    "#                         \"\"\",\n",
    "#                         {\"s\": s, \"o\": o, \"chunk_index\": i},\n",
    "#                     )\n",
    "\n",
    "#     def _deduplicate_entities(self):\n",
    "#         with self.driver.session(database=self.neo4j_database) as session:\n",
    "#             session.run(\"\"\"\n",
    "#             MATCH (e1:Entity), (e2:Entity)\n",
    "#             WHERE e1.name = e2.name AND id(e1) < id(e2)\n",
    "#             CALL apoc.refactor.mergeNodes([e1, e2]) YIELD node\n",
    "#             RETURN count(node)\n",
    "#             \"\"\")\n",
    "\n",
    "#     def run(self, docs: List[Document]):\n",
    "#         print(\"üìÑ Creating chunk nodes...\")\n",
    "#         self._create_chunk_nodes(docs)\n",
    "\n",
    "#         print(\"üîç Extracting triples...\")\n",
    "#         self._create_kg_from_chunks(docs)\n",
    "\n",
    "#         print(\"üßπ Deduplicating entities...\")\n",
    "#         self._deduplicate_entities()\n",
    "\n",
    "#         print(\"‚úÖ Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from neo4j import GraphDatabase\n",
    "from langchain.schema import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class KGTriple(BaseModel):\n",
    "    s: str\n",
    "    p: str\n",
    "    o: str\n",
    "    stype: str = \"Entity\"\n",
    "    otype: str = \"Entity\"\n",
    "\n",
    "\n",
    "class CustomKGPipeline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        driver: GraphDatabase,\n",
    "        embedder,\n",
    "        llm,\n",
    "        domain: str,\n",
    "        ontology: str,\n",
    "        prompt_path: str,\n",
    "        neo4j_database: Optional[str] = None,\n",
    "    ):\n",
    "        self.driver = driver\n",
    "        self.embedder = embedder\n",
    "        self.llm = llm\n",
    "        self.domain = domain\n",
    "        self.ontology = ontology\n",
    "        self.prompt_path = prompt_path\n",
    "        self.neo4j_database = neo4j_database\n",
    "\n",
    "        # We will load these later\n",
    "        self.prompt = None\n",
    "\n",
    "    def _load_prompt(self):\n",
    "        if not os.path.exists(self.prompt_path):\n",
    "            raise FileNotFoundError(f\"Prompt file not found at {self.prompt_path}\")\n",
    "        with open(self.prompt_path, \"r\") as f:\n",
    "            self.template_for_extracting_triples = f.read()\n",
    "\n",
    "\n",
    "    def _render_prompt(self):\n",
    "        if self.prompt is None:\n",
    "            template = self._load_prompt()\n",
    "            self.prompt_template = ChatPromptTemplate.from_template(self.template_for_extracting_triples)\n",
    "        return self.prompt_template\n",
    "    \n",
    "    def _create_chunk_nodes(self, docs: List[Document]):\n",
    "        with self.driver.session(database=self.neo4j_database) as session:\n",
    "            for i, doc in enumerate(docs):\n",
    "                text = doc.page_content\n",
    "                embedding = self.embedder.embed_query(text)\n",
    "\n",
    "                props = {\n",
    "                    \"chunk_index\": i,\n",
    "                    \"text\": text,\n",
    "                    \"embedding\": embedding,\n",
    "                }\n",
    "\n",
    "                # Merge metadata into props\n",
    "                props.update(doc.metadata)\n",
    "\n",
    "                # Create the chunk node\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    MERGE (c:Chunk {chunk_index: $chunk_index})\n",
    "                    SET c += $props\n",
    "                    \"\"\",\n",
    "                    chunk_index=i,\n",
    "                    props=props,\n",
    "                )\n",
    "\n",
    "                # Create NEXT and PREVIOUS links if applicable\n",
    "                if i > 0:\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MATCH (c1:Chunk {chunk_index: $prev}), (c2:Chunk {chunk_index: $curr})\n",
    "                        MERGE (c1)-[:NEXT_CHUNK]->(c2)\n",
    "                        MERGE (c2)-[:PREVIOUS_CHUNK]->(c1)\n",
    "                        \"\"\",\n",
    "                        prev=i - 1,\n",
    "                        curr=i,\n",
    "                    )\n",
    "\n",
    "\n",
    "    def _extract_triples(self, prompt, chunk_text) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Sends the prompt to LLM and parses the output into a list of triple dicts.\n",
    "        Each dict contains 's', 'p', 'o', and optionally 'stype', 'otype', and other properties.\n",
    "        \"\"\"\n",
    "        triple_extracter_chain = prompt | self.llm | StrOutputParser()\n",
    "        response = triple_extracter_chain.invoke({\n",
    "            \"chunk_text\": chunk_text,\n",
    "            \"domain\": self.domain,\n",
    "            \"nl_ontology\": self.ontology\n",
    "        })\n",
    "\n",
    "        try:\n",
    "            raw_triples = ast.literal_eval(response)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to parse response: {e}\")\n",
    "            return []\n",
    "\n",
    "        triples = []\n",
    "        for item in raw_triples:\n",
    "            try:\n",
    "                triple = KGTriple(**item)\n",
    "                triples.append(triple)\n",
    "            except Exception as e:\n",
    "                print(f\"‚õî Invalid triple skipped: {item} due to {e}\")\n",
    "                continue\n",
    "\n",
    "        return triples\n",
    "\n",
    "\n",
    "    def _create_kg_from_chunks(self, docs: List[Document]):\n",
    "        for i, doc in enumerate(docs):\n",
    "            prompt = self._render_prompt()\n",
    "            triples = self._extract_triples(prompt, doc.page_content)\n",
    "\n",
    "            with self.driver.session(database=self.neo4j_database) as session:\n",
    "                for triple in triples:\n",
    "                    s, p, o = triple.s, triple.p, triple.o\n",
    "                    stype, otype = triple.stype, triple.otype\n",
    "\n",
    "                    if not (s and p and o):\n",
    "                        continue\n",
    "\n",
    "                    # Optional properties\n",
    "                    o_props = {\n",
    "                                k: v for k, v in triple.model_dump().items()\n",
    "                                if k not in {\"s\", \"p\", \"o\", \"stype\", \"otype\"}\n",
    "                            }\n",
    "                    # Clean the labels to remove any problematic characters\n",
    "                    def safe_label(label: Optional[str], default=\"Entity\") -> str:\n",
    "                        if not label:\n",
    "                            return default\n",
    "                        return \"\".join(c for c in label if c.isalnum() or c == \"_\") or default\n",
    "\n",
    "                    stype = safe_label(triple.stype)\n",
    "                    otype = safe_label(triple.otype)\n",
    "\n",
    "                    # Create entity nodes and connect\n",
    "                    cypher = f\"\"\"\n",
    "                    MERGE (subj:{stype} {{name: $s}})\n",
    "                    MERGE (obj:{otype} {{name: $o}})\n",
    "                    SET obj += $o_props\n",
    "                    WITH subj, obj\n",
    "                    MATCH (c:Chunk {{chunk_index: $chunk_index}})\n",
    "                    MERGE (subj)-[:MENTIONED_IN]->(c)\n",
    "                    MERGE (obj)-[:MENTIONED_IN]->(c)\n",
    "                    \"\"\"\n",
    "\n",
    "                    session.run(\n",
    "                        cypher,\n",
    "                        {\"s\": s, \"o\": o, \"o_props\": o_props, \"chunk_index\": i},\n",
    "                    )\n",
    "\n",
    "    def _deduplicate_entities(self):\n",
    "        with self.driver.session(database=self.neo4j_database) as session:\n",
    "            session.run(\"\"\"\n",
    "            MATCH (e1:Entity), (e2:Entity)\n",
    "            WHERE e1.name = e2.name AND id(e1) < id(e2)\n",
    "            CALL apoc.refactor.mergeNodes([e1, e2]) YIELD node\n",
    "            RETURN count(node)\n",
    "            \"\"\")\n",
    "\n",
    "    def run(self, docs: List[Document]):\n",
    "        print(\"üìÑ Creating chunk nodes...\")\n",
    "        self._create_chunk_nodes(docs)\n",
    "\n",
    "        print(\"üîç Extracting triples...\")\n",
    "        self._create_kg_from_chunks(docs)\n",
    "\n",
    "        print(\"üßπ Deduplicating entities...\")\n",
    "        self._deduplicate_entities()\n",
    "\n",
    "        print(\"‚úÖ Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = CustomKGPipeline(\n",
    "    driver=driver,\n",
    "    embedder=llm_embedding_large_3,\n",
    "    llm=llm_gpt_4o_mini,\n",
    "    domain=\"Quaterly Financial Reports of Companies\",\n",
    "    ontology=nl_ontology,\n",
    "    prompt_path=\"prompt/updated_prompt.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8abb900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0aec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Creating chunk nodes...\n",
      "üîç Extracting triples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 41, offset: 84} for query: '\\n            MATCH (e1:Entity), (e2:Entity)\\n            WHERE e1.name = e2.name AND id(e1) < id(e2)\\n            CALL apoc.refactor.mergeNodes([e1, e2]) YIELD node\\n            RETURN count(node)\\n            '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 50, offset: 93} for query: '\\n            MATCH (e1:Entity), (e2:Entity)\\n            WHERE e1.name = e2.name AND id(e1) < id(e2)\\n            CALL apoc.refactor.mergeNodes([e1, e2]) YIELD node\\n            RETURN count(node)\\n            '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Deduplicating entities...\n",
      "‚úÖ Done.\n"
     ]
    }
   ],
   "source": [
    "pipeline.run(chunks[20:30])  # Pass each chunk to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf5d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "    session.run(\"DROP INDEX `chunk-index` IF EXISTS\")\n",
    "    session.run(\"CALL apoc.schema.assert({}, {})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ea31f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgneo4jmeta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
