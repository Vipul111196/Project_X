{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c4b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Setup & Imports\n",
    "import os\n",
    "import asyncio\n",
    "from rdflib import Graph as RDFGraph\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "from neo4j_graphrag.indexes import create_vector_index\n",
    "from neo4j_graphrag.embeddings import OpenAIEmbeddings\n",
    "from neo4j_graphrag.llm.openai_llm import OpenAILLM\n",
    "from neo4j_graphrag.experimental.components.text_splitters.fixed_size_splitter import FixedSizeSplitter\n",
    "from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline\n",
    "from neo4j_graphrag.experimental.components.resolver import SinglePropertyExactMatchResolver\n",
    "from neo4j_graphrag.retrievers import VectorRetriever, Text2CypherRetriever\n",
    "from neo4j_graphrag.generation import GraphRAG\n",
    "\n",
    "from src.utils import getSchemaFromOnto, getNLOntology, getPKs\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ffdc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "## 2. Load Environment Variables\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "uri = os.getenv(\"NEO4J_URI\")\n",
    "user = os.getenv(\"NEO4J_USERNAME\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "AUTH = (user, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2856c04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "bolt://localhost:7687\n",
      "neo4j\n",
      "password\n"
     ]
    }
   ],
   "source": [
    "print(api_key)\n",
    "print(uri)\n",
    "print(user)\n",
    "print(password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a79ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(uri, auth=AUTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f71183",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Create Vector Index\n",
    "INDEX_NAME = \"chunk-index\"\n",
    "DIMENSION = 3072\n",
    "create_vector_index(\n",
    "    driver,\n",
    "    INDEX_NAME,\n",
    "    label=\"Chunk\",\n",
    "    embedding_property=\"embedding\",\n",
    "    dimensions=DIMENSION,\n",
    "    similarity_fn=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b593e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader  \n",
    "\n",
    "# Creating a function to read Multiple PDF files  \n",
    "def process_pdfs_in_directory(directory_path):  \n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for filename in os.listdir(directory_path):  \n",
    "        if filename.endswith(\".pdf\"):  \n",
    "            file_path = os.path.join(directory_path, filename) \n",
    "            pdf_loader = PyMuPDFLoader(file_path=file_path)\n",
    "            document = pdf_loader.load()\n",
    "            print(f\"File loading done for: {filename}\")\n",
    "            documents.append(document)\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95dc39b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loading done for: 2022 Q3 AAPL.pdf\n"
     ]
    }
   ],
   "source": [
    "all_docs = process_pdfs_in_directory(\"data/\")  # Specify the directory containing your PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d185e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of basedocs is now 28\n"
     ]
    }
   ],
   "source": [
    "# Initialize the base list  \n",
    "base_docs = []  \n",
    "  \n",
    "# Flatten the all_docs structure and extend base_docs  \n",
    "for doc_list in all_docs:\n",
    "    base_docs.extend(doc_list)  \n",
    "  \n",
    "print('Length of basedocs is now ' + str(len(base_docs))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e2fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of documents saved to data/Pickle_File/base_docs.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle  \n",
    "file_path = 'data/Pickle_File/base_docs.pkl'  \n",
    "  \n",
    "# Serialize the list of Document objects and save it to a file  \n",
    "with open(file_path, 'wb') as file:  \n",
    "    pickle.dump(base_docs, file)  \n",
    "  \n",
    "print(f\"List of documents saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaef308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of documents loaded successfully: 28\n"
     ]
    }
   ],
   "source": [
    "import pickle   \n",
    "  \n",
    "# Specify the file path where your list of documents is saved  \n",
    "file_path = 'data/Pickle_File/base_docs.pkl' \n",
    "  \n",
    "# Deserialize the file content back into a list of Document objects  \n",
    "with open(file_path, 'rb') as file:  \n",
    "    base_docs = pickle.load(file)\n",
    "  \n",
    "print(\"List of documents loaded successfully: \" + str(len(base_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f1d1780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)\n",
    "\n",
    "chunks = text_splitter.split_documents(base_docs)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44dc6712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2022-07-29T06:03:21-04:00', 'source': 'data/2022 Q3 AAPL.pdf', 'file_path': 'data/2022 Q3 AAPL.pdf', 'total_pages': 28, 'format': 'PDF 1.4', 'title': '0000320193-22-000070', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-Q filed on 2022-07-29 for the period ending 2022-06-25', 'keywords': '0000320193-22-000070; ; 10-Q', 'moddate': '2022-07-29T06:03:28-04:00', 'trapped': '', 'encryption': 'Standard V2 R3 128-bit RC4', 'modDate': \"D:20220729060328-04'00'\", 'creationDate': \"D:20220729060321-04'00'\", 'page': 0}, page_content='UNITED STATES\\nSECURITIES AND EXCHANGE COMMISSION\\nWashington, D.C. 20549\\nFORM 10-Q\\n(Mark One)\\n☒ QUARTERLY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\nFor the quarterly period ended June\\xa025, 2022\\nor\\n☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\nFor the transition period from \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 to \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0.\\nCommission File Number: 001-36743\\nApple Inc.\\n(Exact name of Registrant as specified in its charter)\\nCalifornia\\n94-2404110\\n(State or other jurisdiction\\nof incorporation or organization)\\n(I.R.S. Employer Identification No.)\\nOne Apple Park Way\\nCupertino, California\\n95014\\n(Address of principal executive offices)\\n(Zip Code)\\n(408) 996-1010\\n(Registrant’s telephone number, including area code)\\nSecurities registered pursuant to Section 12(b) of the Act:\\nTitle of each class\\nTrading symbol(s)\\nName of each exchange on which registered\\nCommon Stock, $0.00001 par value per share\\nAAPL\\nThe Nasdaq Stock Market LLC\\n1.000% Notes due 2022\\n—\\nThe Nasdaq Stock Market LLC\\n1.375% Notes due 2024\\n—\\nThe Nasdaq Stock Market LLC\\n0.000% Notes due 2025\\n—\\nThe Nasdaq Stock Market LLC\\n0.875% Notes due 2025\\n—\\nThe Nasdaq Stock Market LLC\\n1.625% Notes due 2026\\n—\\nThe Nasdaq Stock Market LLC\\n2.000% Notes due 2027\\n—\\nThe Nasdaq Stock Market LLC\\n1.375% Notes due 2029\\n—\\nThe Nasdaq Stock Market LLC\\n3.050% Notes due 2029\\n—\\nThe Nasdaq Stock Market LLC\\n0.500% Notes due 2031\\n—\\nThe Nasdaq Stock Market LLC\\n3.600% Notes due 2042\\n—')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f6ef97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in chunks:  \n",
    "    del doc.metadata['source']  \n",
    "    file_path = doc.metadata['file_path']  \n",
    "    doc.metadata['file_name'] = os.path.basename(file_path)  \n",
    "    del doc.metadata['file_path']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4056032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2022-07-29T06:03:21-04:00', 'total_pages': 28, 'format': 'PDF 1.4', 'title': '0000320193-22-000070', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-Q filed on 2022-07-29 for the period ending 2022-06-25', 'keywords': '0000320193-22-000070; ; 10-Q', 'moddate': '2022-07-29T06:03:28-04:00', 'trapped': '', 'encryption': 'Standard V2 R3 128-bit RC4', 'modDate': \"D:20220729060328-04'00'\", 'creationDate': \"D:20220729060321-04'00'\", 'page': 0, 'file_name': '2022 Q3 AAPL.pdf'}, page_content='UNITED STATES\\nSECURITIES AND EXCHANGE COMMISSION\\nWashington, D.C. 20549\\nFORM 10-Q\\n(Mark One)\\n☒ QUARTERLY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\nFor the quarterly period ended June\\xa025, 2022\\nor\\n☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\\nFor the transition period from \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 to \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0.\\nCommission File Number: 001-36743\\nApple Inc.\\n(Exact name of Registrant as specified in its charter)\\nCalifornia\\n94-2404110\\n(State or other jurisdiction\\nof incorporation or organization)\\n(I.R.S. Employer Identification No.)\\nOne Apple Park Way\\nCupertino, California\\n95014\\n(Address of principal executive offices)\\n(Zip Code)\\n(408) 996-1010\\n(Registrant’s telephone number, including area code)\\nSecurities registered pursuant to Section 12(b) of the Act:\\nTitle of each class\\nTrading symbol(s)\\nName of each exchange on which registered\\nCommon Stock, $0.00001 par value per share\\nAAPL\\nThe Nasdaq Stock Market LLC\\n1.000% Notes due 2022\\n—\\nThe Nasdaq Stock Market LLC\\n1.375% Notes due 2024\\n—\\nThe Nasdaq Stock Market LLC\\n0.000% Notes due 2025\\n—\\nThe Nasdaq Stock Market LLC\\n0.875% Notes due 2025\\n—\\nThe Nasdaq Stock Market LLC\\n1.625% Notes due 2026\\n—\\nThe Nasdaq Stock Market LLC\\n2.000% Notes due 2027\\n—\\nThe Nasdaq Stock Market LLC\\n1.375% Notes due 2029\\n—\\nThe Nasdaq Stock Market LLC\\n3.050% Notes due 2029\\n—\\nThe Nasdaq Stock Market LLC\\n0.500% Notes due 2031\\n—\\nThe Nasdaq Stock Market LLC\\n3.600% Notes due 2042\\n—')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbb2d1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ex: <http://example.org/financial/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "ex:disclosesRisk a <http://www.w3.org/2002/07/owl#ObjectProperty> ;\n",
      "    rdfs:label \"Discloses Risk\" ;\n",
      "    rdfs:comment \"A report that describes risk factors.\" ;\n",
      "    rdfs:domain ex:FinancialReport ;\n",
      "    rdfs:range ex:RiskFactor .\n",
      "\n",
      "ex:dividendDeclared a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Dividend Declared\" ;\n",
      "    rdfs:comment \"Reported dividend for the time period.\" ;\n",
      "    rdfs:domain ex:FinancialReport .\n",
      "\n",
      "ex:hasStockInfo a <http://www.w3.org/2002/07/owl#ObjectProperty> ;\n",
      "    rdfs:label \"Has Stock Info\" ;\n",
      "    rdfs:comment \"The company has associated stock information.\" ;\n",
      "    rdfs:domain ex:Company ;\n",
      "    rdfs:range ex:StockInformation .\n",
      "\n",
      "ex:includes a <http://www.w3.org/2002/07/owl#ObjectProperty> ;\n",
      "    rdfs:label \"Includes\" ;\n",
      "    rdfs:comment \"A report includes an income statement.\" ;\n",
      "    rdfs:domain ex:FinancialReport ;\n",
      "    rdfs:range ex:IncomeStatement .\n",
      "\n",
      "ex:includesBalance a <http://www.w3.org/2002/07/owl#ObjectProperty> ;\n",
      "    rdfs:label \"Includes Balance Sheet\" ;\n",
      "    rdfs:comment \"A report includes a balance sheet.\" ;\n",
      "    rdfs:domain ex:FinancialReport ;\n",
      "    rdfs:range ex:BalanceSheet .\n",
      "\n",
      "ex:name a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Name\" ;\n",
      "    rdfs:comment \"Official name of the company.\" ;\n",
      "    rdfs:domain ex:Company .\n",
      "\n",
      "ex:relatedTo a <http://www.w3.org/2002/07/owl#ObjectProperty> ;\n",
      "    rdfs:label \"Related To\" ;\n",
      "    rdfs:comment \"The company that filed the report.\" ;\n",
      "    rdfs:domain ex:FinancialReport ;\n",
      "    rdfs:range ex:Company .\n",
      "\n",
      "ex:reportNumber a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Report Number\" ;\n",
      "    rdfs:comment \"The EDGAR report number or filing code.\" ;\n",
      "    rdfs:domain ex:FinancialReport .\n",
      "\n",
      "ex:sharesOutstanding a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Shares Outstanding\" ;\n",
      "    rdfs:comment \"Number of shares available.\" ;\n",
      "    rdfs:domain ex:StockInformation .\n",
      "\n",
      "ex:temporalCoverage a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Temporal Coverage\" ;\n",
      "    rdfs:comment \"Time period covered by the report.\" ;\n",
      "    rdfs:domain ex:FinancialReport .\n",
      "\n",
      "ex:tickerSymbol a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Ticker Symbol\" ;\n",
      "    rdfs:comment \"Stock ticker symbol, e.g. AAPL.\" ;\n",
      "    rdfs:domain ex:Company .\n",
      "\n",
      "ex:unitCode a <http://www.w3.org/2002/07/owl#DatatypeProperty> ;\n",
      "    rdfs:label \"Unit Code\" ;\n",
      "    rdfs:comment \"Currency or measurement unit used.\" ;\n",
      "    rdfs:domain ex:FinancialReport .\n",
      "\n",
      "ex:BalanceSheet a <http://www.w3.org/2002/07/owl#Class> ;\n",
      "    rdfs:label \"Balance Sheet\" ;\n",
      "    rdfs:comment \"Summarizes assets, liabilities, and equity.\" .\n",
      "\n",
      "ex:IncomeStatement a <http://www.w3.org/2002/07/owl#Class> ;\n",
      "    rdfs:label \"Income Statement\" ;\n",
      "    rdfs:comment \"Shows revenue, expenses, and profit.\" .\n",
      "\n",
      "ex:RiskFactor a <http://www.w3.org/2002/07/owl#Class> ;\n",
      "    rdfs:label \"Risk Factor\" ;\n",
      "    rdfs:comment \"Potential risk disclosed by the company.\" .\n",
      "\n",
      "ex:StockInformation a <http://www.w3.org/2002/07/owl#Class> ;\n",
      "    rdfs:label \"Stock Information\" ;\n",
      "    rdfs:comment \"Public stock data reported by the company.\" .\n",
      "\n",
      "ex:Company a <http://www.w3.org/2002/07/owl#Class> ;\n",
      "    rdfs:label \"Company\" ;\n",
      "    rdfs:comment \"A legal entity that files financial reports.\" .\n",
      "\n",
      "ex:FinancialReport a <http://www.w3.org/2002/07/owl#Class> ;\n",
      "    rdfs:label \"Financial Report\" ;\n",
      "    rdfs:comment \"A periodic report (10-K, 10-Q) describing a company's financials.\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"onto/improved_financial_ontology.ttl\", \"r\") as f:\n",
    "    onto = f.read()\n",
    "    print(onto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16832ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SchemaConfig(entities={'FinancialReport': {'label': 'FinancialReport', 'description': 'A 10-Q or 10-K financial disclosure submitted by a public company.', 'properties': [{'name': 'reportNumber', 'type': 'STRING', 'description': 'The SEC form number such as 10-Q or 10-K.'}]}, 'Company': {'label': 'Company', 'description': 'A publicly traded corporation that submits financial reports.', 'properties': []}, 'FinancialStatement': {'label': 'FinancialStatement', 'description': 'A general class for financial statements.', 'properties': []}, 'IncomeStatement': {'label': 'IncomeStatement', 'description': 'An income statement detailing revenue, expenses, and net income.', 'properties': []}, 'BalanceSheet': {'label': 'BalanceSheet', 'description': 'A balance sheet showing assets, liabilities, and equity.', 'properties': []}, 'CashFlowStatement': {'label': 'CashFlowStatement', 'description': 'A statement of cash inflows and outflows.', 'properties': []}, 'ShareholdersEquityStatement': {'label': 'ShareholdersEquityStatement', 'description': 'Tracks changes in equity of shareholders over a period.', 'properties': []}, 'FinancialMetric': {'label': 'FinancialMetric', 'description': 'A quantitative value in a financial report, like Net Income or Revenue.', 'properties': [{'name': 'temporalCoverage', 'type': 'STRING', 'description': 'Time span for which a metric applies (e.g., Q3 2022).'}, {'name': 'unitCode', 'type': 'STRING', 'description': 'Currency or unit, e.g., USD.'}, {'name': 'value', 'type': 'STRING', 'description': 'The actual numeric value of the metric.'}]}, 'StockInformation': {'label': 'StockInformation', 'description': 'Details about company shares, dividends, etc.', 'properties': [{'name': 'tickerSymbol', 'type': 'STRING', 'description': 'The stock ticker symbol, e.g., AAPL, MSFT.'}, {'name': 'sharesOutstanding', 'type': 'STRING', 'description': 'Number of shares currently outstanding.'}, {'name': 'dividendDeclared', 'type': 'STRING', 'description': 'Dividend declared per share for the quarter.'}]}, 'RiskFactor': {'label': 'RiskFactor', 'description': 'Qualitative risks disclosed by a company.', 'properties': []}, 'LegalProceeding': {'label': 'LegalProceeding', 'description': 'A legal action or case referenced in the financial report.', 'properties': []}, 'MarketDisclosure': {'label': 'MarketDisclosure', 'description': 'Narrative discussion on business, market conditions, and trends.', 'properties': []}}, relations={'hasFinancialStatement': {'label': 'hasFinancialStatement', 'description': 'Links a report to the financial statements it contains.', 'properties': []}, 'hasMetric': {'label': 'hasMetric', 'description': 'Connects a statement to its metrics like revenue or net income.', 'properties': []}, 'hasRiskFactor': {'label': 'hasRiskFactor', 'description': 'Connects a report to its described risk factors.', 'properties': []}, 'hasLegalProceeding': {'label': 'hasLegalProceeding', 'description': 'Legal proceedings discussed in the report.', 'properties': []}, 'hasStockInfo': {'label': 'hasStockInfo', 'description': 'Connects the report to stock/share-related data.', 'properties': []}, 'relatedTo': {'label': 'relatedTo', 'description': 'General relationship to a company or segment.', 'properties': []}}, potential_schema=[('FinancialReport', 'hasFinancialStatement', 'FinancialStatement'), ('FinancialStatement', 'hasMetric', 'FinancialMetric'), ('FinancialReport', 'hasRiskFactor', 'RiskFactor'), ('FinancialReport', 'hasLegalProceeding', 'LegalProceeding'), ('FinancialReport', 'hasStockInfo', 'StockInformation'), ('MarketDisclosure', 'relatedTo', 'Company')])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 3. Load Ontology and Schema\n",
    "from IPython.display import display\n",
    "\n",
    "g = RDFGraph()\n",
    "g.parse(\"onto/financial_report_ontology.ttl\")\n",
    "neo4j_schema = getSchemaFromOnto(g) # Load the schema from the ontology\n",
    "display(neo4j_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "52ef8cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FinancialReport', 'hasFinancialStatement', 'FinancialStatement'),\n",
       " ('FinancialStatement', 'hasMetric', 'FinancialMetric'),\n",
       " ('FinancialReport', 'hasRiskFactor', 'RiskFactor'),\n",
       " ('FinancialReport', 'hasLegalProceeding', 'LegalProceeding'),\n",
       " ('FinancialReport', 'hasStockInfo', 'StockInformation'),\n",
       " ('MarketDisclosure', 'relatedTo', 'Company')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo4j_schema.potential_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7b271b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([{'label': 'FinancialReport', 'description': 'A 10-Q or 10-K financial disclosure submitted by a public company.', 'properties': [{'name': 'reportNumber', 'type': 'STRING', 'description': 'The SEC form number such as 10-Q or 10-K.'}]}, {'label': 'Company', 'description': 'A publicly traded corporation that submits financial reports.', 'properties': []}, {'label': 'FinancialStatement', 'description': 'A general class for financial statements.', 'properties': []}, {'label': 'IncomeStatement', 'description': 'An income statement detailing revenue, expenses, and net income.', 'properties': []}, {'label': 'BalanceSheet', 'description': 'A balance sheet showing assets, liabilities, and equity.', 'properties': []}, {'label': 'CashFlowStatement', 'description': 'A statement of cash inflows and outflows.', 'properties': []}, {'label': 'ShareholdersEquityStatement', 'description': 'Tracks changes in equity of shareholders over a period.', 'properties': []}, {'label': 'FinancialMetric', 'description': 'A quantitative value in a financial report, like Net Income or Revenue.', 'properties': [{'name': 'temporalCoverage', 'type': 'STRING', 'description': 'Time span for which a metric applies (e.g., Q3 2022).'}, {'name': 'unitCode', 'type': 'STRING', 'description': 'Currency or unit, e.g., USD.'}, {'name': 'value', 'type': 'STRING', 'description': 'The actual numeric value of the metric.'}]}, {'label': 'StockInformation', 'description': 'Details about company shares, dividends, etc.', 'properties': [{'name': 'tickerSymbol', 'type': 'STRING', 'description': 'The stock ticker symbol, e.g., AAPL, MSFT.'}, {'name': 'sharesOutstanding', 'type': 'STRING', 'description': 'Number of shares currently outstanding.'}, {'name': 'dividendDeclared', 'type': 'STRING', 'description': 'Dividend declared per share for the quarter.'}]}, {'label': 'RiskFactor', 'description': 'Qualitative risks disclosed by a company.', 'properties': []}, {'label': 'LegalProceeding', 'description': 'A legal action or case referenced in the financial report.', 'properties': []}, {'label': 'MarketDisclosure', 'description': 'Narrative discussion on business, market conditions, and trends.', 'properties': []}])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities=neo4j_schema.entities.values()\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99d093c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([{'label': 'hasFinancialStatement', 'description': 'Links a report to the financial statements it contains.', 'properties': []}, {'label': 'hasMetric', 'description': 'Connects a statement to its metrics like revenue or net income.', 'properties': []}, {'label': 'hasRiskFactor', 'description': 'Connects a report to its described risk factors.', 'properties': []}, {'label': 'hasLegalProceeding', 'description': 'Legal proceedings discussed in the report.', 'properties': []}, {'label': 'hasStockInfo', 'description': 'Connects the report to stock/share-related data.', 'properties': []}, {'label': 'relatedTo', 'description': 'General relationship to a company or segment.', 'properties': []}])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations=neo4j_schema.relations.values()\n",
    "relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605ca33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node Labels:\n",
      "FinancialReport: A 10-Q or 10-K financial disclosure submitted by a public company.\n",
      "Company: A publicly traded corporation that submits financial reports.\n",
      "FinancialStatement: A general class for financial statements.\n",
      "IncomeStatement: An income statement detailing revenue, expenses, and net income.\n",
      "BalanceSheet: A balance sheet showing assets, liabilities, and equity.\n",
      "CashFlowStatement: A statement of cash inflows and outflows.\n",
      "ShareholdersEquityStatement: Tracks changes in equity of shareholders over a period.\n",
      "FinancialMetric: A quantitative value in a financial report, like Net Income or Revenue.\n",
      "StockInformation: Details about company shares, dividends, etc.\n",
      "RiskFactor: Qualitative risks disclosed by a company.\n",
      "LegalProceeding: A legal action or case referenced in the financial report.\n",
      "MarketDisclosure: Narrative discussion on business, market conditions, and trends.\n",
      "\n",
      "Node Properties:\n",
      "reportNumber: Attribute that applies to entities of type FinancialReport. It represents The SEC form number such as 10-Q or 10-K.\n",
      "temporalCoverage: Attribute that applies to entities of type FinancialMetric. It represents Time span for which a metric applies (e.g., Q3 2022).\n",
      "unitCode: Attribute that applies to entities of type FinancialMetric. It represents Currency or unit, e.g., USD.\n",
      "value: Attribute that applies to entities of type FinancialMetric. It represents The actual numeric value of the metric.\n",
      "tickerSymbol: Attribute that applies to entities of type StockInformation. It represents The stock ticker symbol, e.g., AAPL, MSFT.\n",
      "sharesOutstanding: Attribute that applies to entities of type StockInformation. It represents Number of shares currently outstanding.\n",
      "dividendDeclared: Attribute that applies to entities of type StockInformation. It represents Dividend declared per share for the quarter.\n",
      "\n",
      "Relationships:\n",
      "hasFinancialStatement: Relationship that connects entities of type FinancialReport to entities of type FinancialStatement. It represents Links a report to the financial statements it contains.\n",
      "hasMetric: Relationship that connects entities of type FinancialStatement to entities of type FinancialMetric. It represents Connects a statement to its metrics like revenue or net income.\n",
      "hasRiskFactor: Relationship that connects entities of type FinancialReport to entities of type RiskFactor. It represents Connects a report to its described risk factors.\n",
      "hasLegalProceeding: Relationship that connects entities of type FinancialReport to entities of type LegalProceeding. It represents Legal proceedings discussed in the report.\n",
      "hasStockInfo: Relationship that connects entities of type FinancialReport to entities of type StockInformation. It represents Connects the report to stock/share-related data.\n",
      "relatedTo: Relationship that connects entities of type MarketDisclosure to entities of type Company. It represents General relationship to a company or segment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nl_ontology = getNLOntology(g)\n",
    "print(nl_ontology) # Load the NL ontology from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e6a9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import KnowledgeGraphLLM\n",
    "# from langchain_ollama import ChatOllama\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "llm_gpt_4o_mini = KnowledgeGraphLLM(model_name=\"gpt-4o-mini\", max_tokens=10000, api_key=api_key)\n",
    "\n",
    "llm_embedding_large_3 = OpenAIEmbeddings(api_key=api_key, model=\"text-embedding-3-large\")\n",
    "\n",
    "# llm_llama31_8b = ChatOllama(\n",
    "#     model=\"llama3.1:8b\",\n",
    "#     temperature=0,\n",
    "#     base_url = \"http://10.5.61.140:5000/\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "706f0149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"s\": \"France\", \"p\": \"hasCapital\", \"o\": \"Paris\", \"stype\": \"Country\", \"otype\": \"City\", \"value\": 0.0, \"unitCode\": \"\", \"temporalCoverage\": \"\", \"tickerSymbol\": \"\", \"dividendDeclared\": 0.0, \"sharesOutstanding\": 0.0, \"reportNumber\": \"\"}]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_gpt_4o_mini.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j_graphrag.embeddings import OpenAIEmbeddings\n",
    "# from neo4j_graphrag.llm.openai_llm import OpenAILLM\n",
    "\n",
    "# embedder = OpenAIEmbeddings(api_key=api_key, model=\"text-embedding-3-large\")\n",
    "# llm = OpenAILLM(api_key=api_key, model_name=\"gpt-4o-mini\", model_params={\"temperature\": 0, \"max_tokens\": 3000, \"response_format\": {\"type\": \"json_object\"}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692fa0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# # Multi Query: Different Perspectives\n",
    "# template_for_extracting_triples = \"\"\"\n",
    "# ### Follow the INSTRUCTION carefully:\n",
    "# You are an expert in **Domain** constructing a **knowledge graph**. Given a **Context** and **Ontologies defined in Natural Language**, **Entities Types**, **Relations Types** which is provided at the end, perform the following tasks:\n",
    "\n",
    "# #### **Step 1: Extract Relevant Entities**\n",
    "# - Extract entites based on the **Ontologies defined in Natural Language** provided below for the Given **Domain** and **Context**.\n",
    "\n",
    "# #### **Step 2: Use only and only the 7 predefined relation types, otherwise, you will be given penalty:**\n",
    "# - Extract relations based on the **Ontologies defined in Natural Language** provided below for the Given **Domain** and **Context**.\n",
    "\n",
    "# #### **Step 3: Identify Relationships and Generate Triplets**\n",
    "# - Determine the **relationships** between the *Entity Types** and the using the **triplet format**: (head_concept, relation, tail_concept)\n",
    "    \n",
    "# - Relationship Directionality: \n",
    "#     - Some relations are strictly directional, meaning (A, Evaluate-for, B) is valid, but (B, Evaluate-for, A) is not.\n",
    "#     - The relations \"Compare\" and \"Conjunction\" are bidirectional.\n",
    "#     - The query concept may be the head or tail in a triplet, but additional triplets between extracted concepts are encouraged.\n",
    "\n",
    "# #### **Step 4: Format the Output only and only use the given format, otherwise, you will be given penalty**\n",
    "# - Return ONLY and ONLY a list of triplets in this format: (concept, relation, concept)\n",
    "# - For Example:\n",
    "#     (natural language explanation, Used-for, model reasoning)\n",
    "#     (natural language explanation, Evaluate-for, classification performance)\n",
    "\n",
    "# #### Boundary Conditions:\n",
    "# - A tuple of triplet is considered eligible if it has only and only 3 items that is 2 concepts and one relationship between them\n",
    "\n",
    "# #### Important notes:\n",
    "# - No additional explanations, numbering, or extra text.\n",
    "\n",
    "# #### Here is the Domain: \n",
    "# {domain}\n",
    "\n",
    "# #### Here is the Ontologies defined in Natural Language:\n",
    "# {nl_ontology}\n",
    "\n",
    "# #### Here is the Context:\n",
    "# {chunk_text}\n",
    "# \"\"\"\n",
    "# prompt_template_for_extracting_triples = ChatPromptTemplate.from_template(template_for_extracting_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = prompt_template_for_extracting_triples.invoke({\"domain\":'Financial Report', \"chunk_text\":base_docs[5].page_content, \"nl_ontology\":nl_ontology})\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad5e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_chain = prompt_template_for_extracting_triples | llm_gpt_4o_mini \n",
    "# response = llm_chain.invoke({\"domain\":'Financial Report', \"chunk_text\":base_docs[5].page_content, \"nl_ontology\":nl_ontology})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227919e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dae0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_json_parse(s):\n",
    "    import ast\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception as e:\n",
    "        print(\"Parsing error:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432b8ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = safe_json_parse(response) # This will return a list of tuples if the parsing is successful, or None if it fails.\n",
    "# print(type(response[0]))\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Optional\n",
    "# from neo4j import GraphDatabase\n",
    "# from langchain.schema import Document\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# import os\n",
    "\n",
    "# class CustomKGPipeline:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         driver: GraphDatabase,\n",
    "#         embedder,\n",
    "#         llm,\n",
    "#         domain: str,\n",
    "#         ontology: str,\n",
    "#         prompt_path: str,\n",
    "#         neo4j_database: Optional[str] = None,\n",
    "#     ):\n",
    "#         self.driver = driver\n",
    "#         self.embedder = embedder\n",
    "#         self.llm = llm\n",
    "#         self.domain = domain\n",
    "#         self.ontology = ontology\n",
    "#         self.prompt_path = prompt_path\n",
    "#         self.neo4j_database = neo4j_database\n",
    "\n",
    "#         # We will load these later\n",
    "#         self.prompt = None\n",
    "\n",
    "#     def _load_prompt(self):\n",
    "#         if not os.path.exists(self.prompt_path):\n",
    "#             raise FileNotFoundError(f\"Prompt file not found at {self.prompt_path}\")\n",
    "#         with open(self.prompt_path, \"r\") as f:\n",
    "#             self.template_for_extracting_triples = f.read()\n",
    "\n",
    "\n",
    "#     def _render_prompt(self):\n",
    "#         if self.prompt is None:\n",
    "#             template = self._load_prompt()\n",
    "#             self.prompt_template = ChatPromptTemplate.from_template(self.template_for_extracting_triples)\n",
    "#         return self.prompt_template\n",
    "    \n",
    "#     def _create_chunk_nodes(self, docs: List[Document]):\n",
    "#         with self.driver.session(database=self.neo4j_database) as session:\n",
    "#             for i, doc in enumerate(docs):\n",
    "#                 text = doc.page_content\n",
    "#                 embedding = self.embedder.embed_query(text)\n",
    "\n",
    "#                 props = {\n",
    "#                     \"chunk_index\": i,\n",
    "#                     \"text\": text,\n",
    "#                     \"embedding\": embedding,\n",
    "#                 }\n",
    "\n",
    "#                 # Merge metadata into props\n",
    "#                 props.update(doc.metadata)\n",
    "\n",
    "#                 # Create the chunk node\n",
    "#                 session.run(\n",
    "#                     \"\"\"\n",
    "#                     MERGE (c:Chunk {chunk_index: $chunk_index})\n",
    "#                     SET c += $props\n",
    "#                     \"\"\",\n",
    "#                     chunk_index=i,\n",
    "#                     props=props,\n",
    "#                 )\n",
    "\n",
    "#                 # Create NEXT and PREVIOUS links if applicable\n",
    "#                 if i > 0:\n",
    "#                     session.run(\n",
    "#                         \"\"\"\n",
    "#                         MATCH (c1:Chunk {chunk_index: $prev}), (c2:Chunk {chunk_index: $curr})\n",
    "#                         MERGE (c1)-[:NEXT_CHUNK]->(c2)\n",
    "#                         MERGE (c2)-[:PREVIOUS_CHUNK]->(c1)\n",
    "#                         \"\"\",\n",
    "#                         prev=i - 1,\n",
    "#                         curr=i,\n",
    "#                     )\n",
    "\n",
    "\n",
    "#     def _extract_triples(self, prompt, chunk_text) -> List[tuple[str, str, str]]:\n",
    "#         \"\"\"\n",
    "#         Sends the prompt to LLM and parses the output into (s, p, o) triples.\n",
    "#         The LLM is expected to return JSON in the format:\n",
    "#         [{\"s\": \"Subject\", \"p\": \"Predicate\", \"o\": \"Object\"}, ...]\n",
    "#         \"\"\"\n",
    "#         triple_extracter_chain = prompt | self.llm | StrOutputParser()\n",
    "#         response = triple_extracter_chain.invoke({\n",
    "#             \"chunk_text\": chunk_text,\n",
    "#             \"domain\": self.domain,\n",
    "#             \"nl_ontology\": self.ontology\n",
    "#         })\n",
    "\n",
    "#         try:\n",
    "#             import ast\n",
    "#             data = ast.literal_eval(response)\n",
    "#         except Exception as e:\n",
    "#             print(\"Failed to parse LLM output:\", e)\n",
    "#             return []\n",
    "\n",
    "#         triples = []\n",
    "#         for item in data:\n",
    "#             s, p, o = item.get(\"s\"), item.get(\"p\"), item.get(\"o\")\n",
    "#             if s and p and o:\n",
    "#                 triples.append((s.strip(), p.strip(), o.strip()))\n",
    "\n",
    "#         return triples\n",
    "\n",
    "\n",
    "#     def _create_kg_from_chunks(self, docs: List[Document]):\n",
    "#         for i, doc in enumerate(docs):\n",
    "#             prompt = self._render_prompt()\n",
    "#             triples = self._extract_triples(prompt, doc.page_content)\n",
    "\n",
    "#             with self.driver.session(database=self.neo4j_database) as session:\n",
    "#                 for s, p, o in triples:\n",
    "#                     if not (s and p and o):\n",
    "#                         continue  # skip malformed ones\n",
    "\n",
    "#                     # Create entity nodes and connect\n",
    "#                     session.run(\n",
    "#                         f\"\"\"\n",
    "#                         MERGE (subj:Entity {{name: $s}})\n",
    "#                         MERGE (obj:Entity {{name: $o}})\n",
    "#                         MERGE (subj)-[:{p.upper()}]->(obj)\n",
    "#                         WITH subj, obj\n",
    "#                         MATCH (c:Chunk {{chunk_index: $chunk_index}})\n",
    "#                         MERGE (subj)-[:MENTIONED_IN]->(c)\n",
    "#                         MERGE (obj)-[:MENTIONED_IN]->(c)\n",
    "#                         \"\"\",\n",
    "#                         {\"s\": s, \"o\": o, \"chunk_index\": i},\n",
    "#                     )\n",
    "\n",
    "#     def _deduplicate_entities(self):\n",
    "#         with self.driver.session(database=self.neo4j_database) as session:\n",
    "#             session.run(\"\"\"\n",
    "#             MATCH (e1:Entity), (e2:Entity)\n",
    "#             WHERE e1.name = e2.name AND id(e1) < id(e2)\n",
    "#             CALL apoc.refactor.mergeNodes([e1, e2]) YIELD node\n",
    "#             RETURN count(node)\n",
    "#             \"\"\")\n",
    "\n",
    "#     def run(self, docs: List[Document]):\n",
    "#         print(\"📄 Creating chunk nodes...\")\n",
    "#         self._create_chunk_nodes(docs)\n",
    "\n",
    "#         print(\"🔍 Extracting triples...\")\n",
    "#         self._create_kg_from_chunks(docs)\n",
    "\n",
    "#         print(\"🧹 Deduplicating entities...\")\n",
    "#         self._deduplicate_entities()\n",
    "\n",
    "#         print(\"✅ Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from neo4j import GraphDatabase\n",
    "from langchain.schema import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class KGTriple(BaseModel):\n",
    "    s: str\n",
    "    p: str\n",
    "    o: str\n",
    "    stype: str = \"Entity\"\n",
    "    otype: str = \"Entity\"\n",
    "\n",
    "\n",
    "class CustomKGPipeline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        driver: GraphDatabase,\n",
    "        embedder,\n",
    "        llm,\n",
    "        domain: str,\n",
    "        ontology: str,\n",
    "        prompt_path: str,\n",
    "        neo4j_database: Optional[str] = None,\n",
    "    ):\n",
    "        self.driver = driver\n",
    "        self.embedder = embedder\n",
    "        self.llm = llm\n",
    "        self.domain = domain\n",
    "        self.ontology = ontology\n",
    "        self.prompt_path = prompt_path\n",
    "        self.neo4j_database = neo4j_database\n",
    "\n",
    "        # We will load these later\n",
    "        self.prompt = None\n",
    "\n",
    "    def _load_prompt(self):\n",
    "        if not os.path.exists(self.prompt_path):\n",
    "            raise FileNotFoundError(f\"Prompt file not found at {self.prompt_path}\")\n",
    "        with open(self.prompt_path, \"r\") as f:\n",
    "            self.template_for_extracting_triples = f.read()\n",
    "\n",
    "\n",
    "    def _render_prompt(self):\n",
    "        if self.prompt is None:\n",
    "            template = self._load_prompt()\n",
    "            self.prompt_template = ChatPromptTemplate.from_template(self.template_for_extracting_triples)\n",
    "        return self.prompt_template\n",
    "    \n",
    "    def _create_chunk_nodes(self, docs: List[Document]):\n",
    "        with self.driver.session(database=self.neo4j_database) as session:\n",
    "            for i, doc in enumerate(docs):\n",
    "                text = doc.page_content\n",
    "                embedding = self.embedder.embed_query(text)\n",
    "\n",
    "                props = {\n",
    "                    \"chunk_index\": i,\n",
    "                    \"text\": text,\n",
    "                    \"embedding\": embedding,\n",
    "                }\n",
    "\n",
    "                # Merge metadata into props\n",
    "                props.update(doc.metadata)\n",
    "\n",
    "                # Create the chunk node\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    MERGE (c:Chunk {chunk_index: $chunk_index})\n",
    "                    SET c += $props\n",
    "                    \"\"\",\n",
    "                    chunk_index=i,\n",
    "                    props=props,\n",
    "                )\n",
    "\n",
    "                # Create NEXT and PREVIOUS links if applicable\n",
    "                if i > 0:\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MATCH (c1:Chunk {chunk_index: $prev}), (c2:Chunk {chunk_index: $curr})\n",
    "                        MERGE (c1)-[:NEXT_CHUNK]->(c2)\n",
    "                        MERGE (c2)-[:PREVIOUS_CHUNK]->(c1)\n",
    "                        \"\"\",\n",
    "                        prev=i - 1,\n",
    "                        curr=i,\n",
    "                    )\n",
    "\n",
    "\n",
    "    def _extract_triples(self, prompt, chunk_text) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Sends the prompt to LLM and parses the output into a list of triple dicts.\n",
    "        Each dict contains 's', 'p', 'o', and optionally 'stype', 'otype', and other properties.\n",
    "        \"\"\"\n",
    "        triple_extracter_chain = prompt | self.llm | StrOutputParser()\n",
    "        response = triple_extracter_chain.invoke({\n",
    "            \"chunk_text\": chunk_text,\n",
    "            \"domain\": self.domain,\n",
    "            \"nl_ontology\": self.ontology\n",
    "        })\n",
    "\n",
    "        try:\n",
    "            raw_triples = ast.literal_eval(response)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to parse response: {e}\")\n",
    "            return []\n",
    "\n",
    "        triples = []\n",
    "        for item in raw_triples:\n",
    "            try:\n",
    "                triple = KGTriple(**item)\n",
    "                triples.append(triple)\n",
    "            except Exception as e:\n",
    "                print(f\"⛔ Invalid triple skipped: {item} due to {e}\")\n",
    "                continue\n",
    "\n",
    "        return triples\n",
    "\n",
    "\n",
    "    def _create_kg_from_chunks(self, docs: List[Document]):\n",
    "        for i, doc in enumerate(docs):\n",
    "            prompt = self._render_prompt()\n",
    "            triples = self._extract_triples(prompt, doc.page_content)\n",
    "\n",
    "            with self.driver.session(database=self.neo4j_database) as session:\n",
    "                for triple in triples:\n",
    "                    s, p, o = triple.s, triple.p, triple.o\n",
    "                    stype, otype = triple.stype, triple.otype\n",
    "\n",
    "                    if not (s and p and o):\n",
    "                        continue\n",
    "\n",
    "                    # Optional properties\n",
    "                    o_props = {\n",
    "                                k: v for k, v in triple.model_dump().items()\n",
    "                                if k not in {\"s\", \"p\", \"o\", \"stype\", \"otype\"}\n",
    "                            }\n",
    "                    # Clean the labels to remove any problematic characters\n",
    "                    def safe_label(label: Optional[str], default=\"Entity\") -> str:\n",
    "                        if not label:\n",
    "                            return default\n",
    "                        return \"\".join(c for c in label if c.isalnum() or c == \"_\") or default\n",
    "\n",
    "                    stype = safe_label(triple.stype)\n",
    "                    otype = safe_label(triple.otype)\n",
    "\n",
    "                    # Create entity nodes and connect\n",
    "                    cypher = f\"\"\"\n",
    "                    MERGE (subj:{stype} {{name: $s}})\n",
    "                    MERGE (obj:{otype} {{name: $o}})\n",
    "                    SET obj += $o_props\n",
    "                    WITH subj, obj\n",
    "                    MATCH (c:Chunk {{chunk_index: $chunk_index}})\n",
    "                    MERGE (subj)-[:MENTIONED_IN]->(c)\n",
    "                    MERGE (obj)-[:MENTIONED_IN]->(c)\n",
    "                    \"\"\"\n",
    "\n",
    "                    session.run(\n",
    "                        cypher,\n",
    "                        {\"s\": s, \"o\": o, \"o_props\": o_props, \"chunk_index\": i},\n",
    "                    )\n",
    "\n",
    "    def _deduplicate_entities(self):\n",
    "        with self.driver.session(database=self.neo4j_database) as session:\n",
    "            session.run(\"\"\"\n",
    "            MATCH (e1:Entity), (e2:Entity)\n",
    "            WHERE e1.name = e2.name AND id(e1) < id(e2)\n",
    "            CALL apoc.refactor.mergeNodes([e1, e2]) YIELD node\n",
    "            RETURN count(node)\n",
    "            \"\"\")\n",
    "\n",
    "    def run(self, docs: List[Document]):\n",
    "        print(\"📄 Creating chunk nodes...\")\n",
    "        self._create_chunk_nodes(docs)\n",
    "\n",
    "        print(\"🔍 Extracting triples...\")\n",
    "        self._create_kg_from_chunks(docs)\n",
    "\n",
    "        print(\"🧹 Deduplicating entities...\")\n",
    "        self._deduplicate_entities()\n",
    "\n",
    "        print(\"✅ Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = CustomKGPipeline(\n",
    "    driver=driver,\n",
    "    embedder=llm_embedding_large_3,\n",
    "    llm=llm_gpt_4o_mini,\n",
    "    domain=\"Quaterly Financial Reports of Companies\",\n",
    "    ontology=nl_ontology,\n",
    "    prompt_path=\"prompt/updated_prompt.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8abb900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0aec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Creating chunk nodes...\n",
      "🔍 Extracting triples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 41, offset: 84} for query: '\\n            MATCH (e1:Entity), (e2:Entity)\\n            WHERE e1.name = e2.name AND id(e1) < id(e2)\\n            CALL apoc.refactor.mergeNodes([e1, e2]) YIELD node\\n            RETURN count(node)\\n            '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 50, offset: 93} for query: '\\n            MATCH (e1:Entity), (e2:Entity)\\n            WHERE e1.name = e2.name AND id(e1) < id(e2)\\n            CALL apoc.refactor.mergeNodes([e1, e2]) YIELD node\\n            RETURN count(node)\\n            '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Deduplicating entities...\n",
      "✅ Done.\n"
     ]
    }
   ],
   "source": [
    "pipeline.run(chunks[20:30])  # Pass each chunk to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf5d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "    session.run(\"DROP INDEX `chunk-index` IF EXISTS\")\n",
    "    session.run(\"CALL apoc.schema.assert({}, {})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ea31f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgneo4jmeta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
